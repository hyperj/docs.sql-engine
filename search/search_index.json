{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 \u5f53\u524d\u7248\u672c\u57fa\u4e8e Spark SQL 2.x \u8fdb\u884c\u6574\u7406\uff0c\u53c2\u8003\u4e86\u4e3b\u6d41\u5206\u5e03\u5f0f SQL \u8ba1\u7b97\u5f15\u64ce\u76f8\u5173\u7684\u5f00\u6e90\u9879\u76ee\u3002 Spark Core\uff08RDD APIs\uff09\u3001Data Source Connectors Catalyst Optimization\u3001Tungsten Execution SparkSession\u3001Dataset/DataFrame APIs\u3001SQL Structured Streaming\u3001MLlib\u3001GraphFrame\u3001TensorFrames Reference \u00b6 Spark SQL : Spark SQL is Apache Spark's module for working with structured data. Hive : The Apache Hive \u2122 data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive. Presto : Distributed SQL Query Engine for Big Data.","title":"\u9996\u9875"},{"location":"#introduction","text":"\u5f53\u524d\u7248\u672c\u57fa\u4e8e Spark SQL 2.x \u8fdb\u884c\u6574\u7406\uff0c\u53c2\u8003\u4e86\u4e3b\u6d41\u5206\u5e03\u5f0f SQL \u8ba1\u7b97\u5f15\u64ce\u76f8\u5173\u7684\u5f00\u6e90\u9879\u76ee\u3002 Spark Core\uff08RDD APIs\uff09\u3001Data Source Connectors Catalyst Optimization\u3001Tungsten Execution SparkSession\u3001Dataset/DataFrame APIs\u3001SQL Structured Streaming\u3001MLlib\u3001GraphFrame\u3001TensorFrames","title":"Introduction"},{"location":"#reference","text":"Spark SQL : Spark SQL is Apache Spark's module for working with structured data. Hive : The Apache Hive \u2122 data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive. Presto : Distributed SQL Query Engine for Big Data.","title":"Reference"},{"location":"todo/","text":"","title":"TODO"},{"location":"antlr/overview/","text":"TODO \u00b6 Reference \u00b6 Docs Github","title":"Antlr"},{"location":"antlr/overview/#todo","text":"","title":"TODO"},{"location":"antlr/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"appendix/appendix-a-spark/","text":"\u9644\u5f55 A - Spark \u00b6 Application -1:n-> Session(Context) -1:n-> Job -1:n-> Stage Task -1:n-> Partition -1:n-> Block Configuration \u00b6 Application Properties \u00b6 \u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 spark.driver.memory - 1g 2g, 4g Driver \u5185\u5b58 spark.driver.cores - 1 2, 4 Driver \u6838\u6570 spark.executor.memory - 1g 4g, 16g Executor \u5185\u5b58 spark.executor.cores - 1 2, 8 Executor \u6838\u6570 Runtime Environment \u00b6 Shuffle Behavior \u00b6 Compression and Serialization \u00b6 Memory Management \u00b6 Execution Behavior \u00b6 Networking \u00b6 Scheduling \u00b6 Dynamic Allocation \u00b6 Spark SQL \u00b6 \u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 spark.sql.shuffle.partitions - 200 20, 400 Shuffle\u5206\u533a\u6570\u91cf\uff08Join\u3001Aggr\uff09 spark.sql.autoBroadcastJoinThreshold - 10L * 1024 * 1024 (32, 64) * 1024 * 1024 \u81ea\u52a8\u4f18\u5316\u4e3aBroadcastJoin\u9608\u503c spark.sql.adaptive.enabled - false true \u81ea\u9002\u5e94\u67e5\u8be2\u6267\u884c\uff08Broadcast\u3001Partition\u3001Skew\uff09 spark.sql.adaptive.shuffle.targetPostShuffleInputSize - 64 * 1024 * 1024 (32, 128) * 1024 * 1024 Shuffle\u8bfb\u53d6\u6587\u4ef6\u5927\u5c0f spark.sql.adaptive.minNumPostShufflePartitions - -1 10, 200 Shuffle\u6700\u5c0f\u5206\u533a\u6570\u91cf Yarn \u00b6 Hive \u00b6 \u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 hive.exec.dynamic.partition - false true \u5141\u8bb8\u52a8\u6001\u5206\u533a hive.exec.dynamic.partition.mode - strict nonstrict \u52a8\u6001\u5206\u533a\u6a21\u5f0f hive.exec.max.dynamic.partitions - 1000 100-1000 \u5141\u8bb8\u521b\u5efa\u6700\u5927\u5206\u533a\u6570 MapReduce \u00b6 HDFS \u00b6 JVM \u00b6 Reference \u00b6 Spark Configuration SQLConf.scala","title":"\u9644\u5f55 A - Spark"},{"location":"appendix/appendix-a-spark/#a-spark","text":"Application -1:n-> Session(Context) -1:n-> Job -1:n-> Stage Task -1:n-> Partition -1:n-> Block","title":"\u9644\u5f55 A - Spark"},{"location":"appendix/appendix-a-spark/#configuration","text":"","title":"Configuration"},{"location":"appendix/appendix-a-spark/#application-properties","text":"\u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 spark.driver.memory - 1g 2g, 4g Driver \u5185\u5b58 spark.driver.cores - 1 2, 4 Driver \u6838\u6570 spark.executor.memory - 1g 4g, 16g Executor \u5185\u5b58 spark.executor.cores - 1 2, 8 Executor \u6838\u6570","title":"Application Properties"},{"location":"appendix/appendix-a-spark/#runtime-environment","text":"","title":"Runtime Environment"},{"location":"appendix/appendix-a-spark/#shuffle-behavior","text":"","title":"Shuffle Behavior"},{"location":"appendix/appendix-a-spark/#compression-and-serialization","text":"","title":"Compression and Serialization"},{"location":"appendix/appendix-a-spark/#memory-management","text":"","title":"Memory Management"},{"location":"appendix/appendix-a-spark/#execution-behavior","text":"","title":"Execution Behavior"},{"location":"appendix/appendix-a-spark/#networking","text":"","title":"Networking"},{"location":"appendix/appendix-a-spark/#scheduling","text":"","title":"Scheduling"},{"location":"appendix/appendix-a-spark/#dynamic-allocation","text":"","title":"Dynamic Allocation"},{"location":"appendix/appendix-a-spark/#spark-sql","text":"\u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 spark.sql.shuffle.partitions - 200 20, 400 Shuffle\u5206\u533a\u6570\u91cf\uff08Join\u3001Aggr\uff09 spark.sql.autoBroadcastJoinThreshold - 10L * 1024 * 1024 (32, 64) * 1024 * 1024 \u81ea\u52a8\u4f18\u5316\u4e3aBroadcastJoin\u9608\u503c spark.sql.adaptive.enabled - false true \u81ea\u9002\u5e94\u67e5\u8be2\u6267\u884c\uff08Broadcast\u3001Partition\u3001Skew\uff09 spark.sql.adaptive.shuffle.targetPostShuffleInputSize - 64 * 1024 * 1024 (32, 128) * 1024 * 1024 Shuffle\u8bfb\u53d6\u6587\u4ef6\u5927\u5c0f spark.sql.adaptive.minNumPostShufflePartitions - -1 10, 200 Shuffle\u6700\u5c0f\u5206\u533a\u6570\u91cf","title":"Spark SQL"},{"location":"appendix/appendix-a-spark/#yarn","text":"","title":"Yarn"},{"location":"appendix/appendix-a-spark/#hive","text":"\u540d\u79f0 \u7248\u672c \u9ed8\u8ba4\u503c \u63a8\u8350\u503c \u542b\u4e49 hive.exec.dynamic.partition - false true \u5141\u8bb8\u52a8\u6001\u5206\u533a hive.exec.dynamic.partition.mode - strict nonstrict \u52a8\u6001\u5206\u533a\u6a21\u5f0f hive.exec.max.dynamic.partitions - 1000 100-1000 \u5141\u8bb8\u521b\u5efa\u6700\u5927\u5206\u533a\u6570","title":"Hive"},{"location":"appendix/appendix-a-spark/#mapreduce","text":"","title":"MapReduce"},{"location":"appendix/appendix-a-spark/#hdfs","text":"","title":"HDFS"},{"location":"appendix/appendix-a-spark/#jvm","text":"","title":"JVM"},{"location":"appendix/appendix-a-spark/#reference","text":"Spark Configuration SQLConf.scala","title":"Reference"},{"location":"appendix/appendix-b-spark/","text":"\u9644\u5f55 B - Spark \u00b6 \u6570\u636e\u7c7b\u578b\uff08Data Types\uff09 \u00b6 Spark SQL and DataFrames support the following data types: Numeric types ByteType: Represents 1-byte signed integer numbers. The range of numbers is from -128 to 127. ShortType: Represents 2-byte signed integer numbers. The range of numbers is from -32768 to 32767. IntegerType: Represents 4-byte signed integer numbers. The range of numbers is from -2147483648 to 2147483647. LongType: Represents 8-byte signed integer numbers. The range of numbers is from -9223372036854775808 to 9223372036854775807. FloatType: Represents 4-byte single-precision floating point numbers. DoubleType: Represents 8-byte double-precision floating point numbers. DecimalType: Represents arbitrary-precision signed decimal numbers. Backed internally by java.math.BigDecimal. A BigDecimal consists of an arbitrary precision integer unscaled value and a 32-bit integer scale. String type StringType: Represents character string values. Binary type BinaryType: Represents byte sequence values. Boolean type BooleanType: Represents boolean values. Datetime type TimestampType: Represents values comprising values of fields year, month, day, hour, minute, and second. DateType: Represents values comprising values of fields year, month, day. Complex types ArrayType(elementType, containsNull): Represents values comprising a sequence of elements with the type of elementType. containsNull is used to indicate if elements in a ArrayType value can have null values. MapType(keyType, valueType, valueContainsNull): Represents values comprising a set of key-value pairs. The data type of keys are described by keyType and the data type of values are described by valueType. For a MapType value, keys are not allowed to have null values. valueContainsNull is used to indicate if values of a MapType value can have null values. StructType(fields): Represents values with the structure described by a sequence of StructFields (fields). StructField(name, dataType, nullable): Represents a field in a StructType. The name of a field is indicated by name. The data type of a field is indicated by dataType. nullable is used to indicate if values of this fields can have null values. Manual \u00b6 DDL (Data Definition Language) \u00b6 CREATE/DROP/ALTER/TRUNCATE/SHOW/DESCRIBE DATABASE/TABLE/COLUMN/VIEW/ INDEX/MACRO /FUNCTION DML (Data Manipulation Language) \u00b6 LOAD/INSERT/ UPDATE/DELETE/MERGE IMPORT/EXPORT EXPLAIN DQL (Data Query Language) \u00b6 SELECT DCL (Data Control Language) \u00b6 GRANT/REVOKE ROLE/PRIVILEGE DTL (Data Transaction Language) \u00b6 LOCKS/TRANSACTIONS/COMPACTIONS Functions \u00b6 array_distinct \u00b6 array_distinct(array) - Removes duplicate values from the array. Examples: > SELECT array_distinct ( array ( 1 , 2 , 3 , null , 3 )); [ 1 , 2 , 3 , null ] Since: 2.4.0 array_except \u00b6 array_except(array1, array2) - Returns an array of the elements in array1 but not in array2, without duplicates. Examples: > SELECT array_except ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 2 ] Since: 2.4.0 array_intersect \u00b6 array_intersect(array1, array2) - Returns an array of the elements in the intersection of array1 and array2, without duplicates. Examples: > SELECT array_intersect ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 1 , 3 ] Since: 2.4.0 array_join \u00b6 array_join(array, delimiter[, nullReplacement]) - Concatenates the elements of the given array using the delimiter and an optional string to replace nulls. If no value is set for nullReplacement, any null value is filtered. Examples: > SELECT array_join ( array ( 'hello' , 'world' ), ' ' ); hello world > SELECT array_join ( array ( 'hello' , null , 'world' ), ' ' ); hello world > SELECT array_join ( array ( 'hello' , null , 'world' ), ' ' , ',' ); hello , world Since: 2.4.0 array_max \u00b6 array_max(array) - Returns the maximum value in the array. NULL elements are skipped. Examples: > SELECT array_max ( array ( 1 , 20 , null , 3 )); 20 Since: 2.4.0 array_min \u00b6 array_min(array) - Returns the minimum value in the array. NULL elements are skipped. Examples: > SELECT array_min ( array ( 1 , 20 , null , 3 )); 1 Since: 2.4.0 array_position \u00b6 array_position(array, element) - Returns the (1-based) index of the first element of the array as long. Examples: > SELECT array_position ( array ( 3 , 2 , 1 ), 1 ); 3 Since: 2.4.0 array_remove \u00b6 array_remove(array, element) - Remove all elements that equal to element from array. Examples: > SELECT array_remove ( array ( 1 , 2 , 3 , null , 3 ), 3 ); [ 1 , 2 , null ] Since: 2.4.0 array_repeat \u00b6 array_repeat(element, count) - Returns the array containing element count times. Examples: > SELECT array_repeat ( '123' , 2 ); [ \"123\" , \"123\" ] Since: 2.4.0 array_sort \u00b6 array_sort(array) - Sorts the input array in ascending order. The elements of the input array must be orderable. Null elements will be placed at the end of the returned array. Examples: > SELECT array_sort ( array ( 'b' , 'd' , null , 'c' , 'a' )); [ \"a\" , \"b\" , \"c\" , \"d\" , null ] Since: 2.4.0 array_union \u00b6 array_union(array1, array2) - Returns an array of the elements in the union of array1 and array2, without duplicates. Examples: > SELECT array_union ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 1 , 2 , 3 , 5 ] Since: 2.4.0 arrays_overlap \u00b6 arrays_overlap(a1, a2) - Returns true if a1 contains at least a non-null element present also in a2. If the arrays have no common element and they are both non-empty and either of them contains a null element null is returned, false otherwise. Examples: > SELECT arrays_overlap ( array ( 1 , 2 , 3 ), array ( 3 , 4 , 5 )); true Since: 2.4.0 arrays_zip \u00b6 arrays_zip(a1, a2, ...) - Returns a merged array of structs in which the N-th struct contains all N-th values of input arrays. Examples: > SELECT arrays_zip ( array ( 1 , 2 , 3 ), array ( 2 , 3 , 4 )); [ { \"0\" : 1 , \"1\" : 2 } , { \"0\" : 2 , \"1\" : 3 } , { \"0\" : 3 , \"1\" : 4 } ] > SELECT arrays_zip ( array ( 1 , 2 ), array ( 2 , 3 ), array ( 3 , 4 )); [ { \"0\" : 1 , \"1\" : 2 , \"2\" : 3 } , { \"0\" : 2 , \"1\" : 3 , \"2\" : 4 } ] Since: 2.4.0 from_json \u00b6 from_json(jsonStr, schema[, options]) - Returns a struct value with the given jsonStr and schema. Examples: > SELECT from_json ( '{\"a\":1, \"b\":0.8}' , 'a INT, b DOUBLE' ); { \"a\" : 1 , \"b\" : 0 . 8 } > SELECT from_json ( '{\"time\":\"26/08/2015\"}' , 'time Timestamp' , map ( 'timestampFormat' , 'dd/MM/yyyy' )); { \"time\" : \"2015-08-26 00:00:00.0\" } Since: 2.2.0 to_json \u00b6 to_json(expr[, options]) - Returns a json string with a given struct value Examples: > SELECT to_json ( named_struct ( 'a' , 1 , 'b' , 2 )); { \"a\" : 1 , \"b\" : 2 } > SELECT to_json ( named_struct ( 'time' , to_timestamp ( '2015-08-26' , 'yyyy-MM-dd' )), map ( 'timestampFormat' , 'dd/MM/yyyy' )); { \"time\" : \"26/08/2015\" } > SELECT to_json ( array ( named_struct ( 'a' , 1 , 'b' , 2 )); [ { \"a\" : 1 , \"b\" : 2 } ] > SELECT to_json ( map ( 'a' , named_struct ( 'b' , 1 ))); { \"a\" : { \"b\" : 1 }} > SELECT to_json ( map ( named_struct ( 'a' , 1 ), named_struct ( 'b' , 2 ))); { \"[1]\" : { \"b\" : 2 }} > SELECT to_json ( map ( 'a' , 1 )); { \"a\" : 1 } > SELECT to_json ( array (( map ( 'a' , 1 )))); [ { \"a\" : 1 } ] Since: 2.2.0 Reference \u00b6 Spark SQL, Built-in Functions","title":"\u9644\u5f55 B - Spark"},{"location":"appendix/appendix-b-spark/#b-spark","text":"","title":"\u9644\u5f55 B - Spark"},{"location":"appendix/appendix-b-spark/#data-types","text":"Spark SQL and DataFrames support the following data types: Numeric types ByteType: Represents 1-byte signed integer numbers. The range of numbers is from -128 to 127. ShortType: Represents 2-byte signed integer numbers. The range of numbers is from -32768 to 32767. IntegerType: Represents 4-byte signed integer numbers. The range of numbers is from -2147483648 to 2147483647. LongType: Represents 8-byte signed integer numbers. The range of numbers is from -9223372036854775808 to 9223372036854775807. FloatType: Represents 4-byte single-precision floating point numbers. DoubleType: Represents 8-byte double-precision floating point numbers. DecimalType: Represents arbitrary-precision signed decimal numbers. Backed internally by java.math.BigDecimal. A BigDecimal consists of an arbitrary precision integer unscaled value and a 32-bit integer scale. String type StringType: Represents character string values. Binary type BinaryType: Represents byte sequence values. Boolean type BooleanType: Represents boolean values. Datetime type TimestampType: Represents values comprising values of fields year, month, day, hour, minute, and second. DateType: Represents values comprising values of fields year, month, day. Complex types ArrayType(elementType, containsNull): Represents values comprising a sequence of elements with the type of elementType. containsNull is used to indicate if elements in a ArrayType value can have null values. MapType(keyType, valueType, valueContainsNull): Represents values comprising a set of key-value pairs. The data type of keys are described by keyType and the data type of values are described by valueType. For a MapType value, keys are not allowed to have null values. valueContainsNull is used to indicate if values of a MapType value can have null values. StructType(fields): Represents values with the structure described by a sequence of StructFields (fields). StructField(name, dataType, nullable): Represents a field in a StructType. The name of a field is indicated by name. The data type of a field is indicated by dataType. nullable is used to indicate if values of this fields can have null values.","title":"\u6570\u636e\u7c7b\u578b\uff08Data Types\uff09"},{"location":"appendix/appendix-b-spark/#manual","text":"","title":"Manual"},{"location":"appendix/appendix-b-spark/#ddl-data-definition-language","text":"CREATE/DROP/ALTER/TRUNCATE/SHOW/DESCRIBE DATABASE/TABLE/COLUMN/VIEW/ INDEX/MACRO /FUNCTION","title":"DDL (Data Definition Language)"},{"location":"appendix/appendix-b-spark/#dml-data-manipulation-language","text":"LOAD/INSERT/ UPDATE/DELETE/MERGE IMPORT/EXPORT EXPLAIN","title":"DML (Data Manipulation Language)"},{"location":"appendix/appendix-b-spark/#dql-data-query-language","text":"SELECT","title":"DQL (Data Query Language)"},{"location":"appendix/appendix-b-spark/#dcl-data-control-language","text":"GRANT/REVOKE ROLE/PRIVILEGE","title":"DCL (Data Control Language)"},{"location":"appendix/appendix-b-spark/#dtl-data-transaction-language","text":"LOCKS/TRANSACTIONS/COMPACTIONS","title":"DTL (Data Transaction Language)"},{"location":"appendix/appendix-b-spark/#functions","text":"","title":"Functions"},{"location":"appendix/appendix-b-spark/#array_distinct","text":"array_distinct(array) - Removes duplicate values from the array. Examples: > SELECT array_distinct ( array ( 1 , 2 , 3 , null , 3 )); [ 1 , 2 , 3 , null ] Since: 2.4.0","title":"array_distinct"},{"location":"appendix/appendix-b-spark/#array_except","text":"array_except(array1, array2) - Returns an array of the elements in array1 but not in array2, without duplicates. Examples: > SELECT array_except ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 2 ] Since: 2.4.0","title":"array_except"},{"location":"appendix/appendix-b-spark/#array_intersect","text":"array_intersect(array1, array2) - Returns an array of the elements in the intersection of array1 and array2, without duplicates. Examples: > SELECT array_intersect ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 1 , 3 ] Since: 2.4.0","title":"array_intersect"},{"location":"appendix/appendix-b-spark/#array_join","text":"array_join(array, delimiter[, nullReplacement]) - Concatenates the elements of the given array using the delimiter and an optional string to replace nulls. If no value is set for nullReplacement, any null value is filtered. Examples: > SELECT array_join ( array ( 'hello' , 'world' ), ' ' ); hello world > SELECT array_join ( array ( 'hello' , null , 'world' ), ' ' ); hello world > SELECT array_join ( array ( 'hello' , null , 'world' ), ' ' , ',' ); hello , world Since: 2.4.0","title":"array_join"},{"location":"appendix/appendix-b-spark/#array_max","text":"array_max(array) - Returns the maximum value in the array. NULL elements are skipped. Examples: > SELECT array_max ( array ( 1 , 20 , null , 3 )); 20 Since: 2.4.0","title":"array_max"},{"location":"appendix/appendix-b-spark/#array_min","text":"array_min(array) - Returns the minimum value in the array. NULL elements are skipped. Examples: > SELECT array_min ( array ( 1 , 20 , null , 3 )); 1 Since: 2.4.0","title":"array_min"},{"location":"appendix/appendix-b-spark/#array_position","text":"array_position(array, element) - Returns the (1-based) index of the first element of the array as long. Examples: > SELECT array_position ( array ( 3 , 2 , 1 ), 1 ); 3 Since: 2.4.0","title":"array_position"},{"location":"appendix/appendix-b-spark/#array_remove","text":"array_remove(array, element) - Remove all elements that equal to element from array. Examples: > SELECT array_remove ( array ( 1 , 2 , 3 , null , 3 ), 3 ); [ 1 , 2 , null ] Since: 2.4.0","title":"array_remove"},{"location":"appendix/appendix-b-spark/#array_repeat","text":"array_repeat(element, count) - Returns the array containing element count times. Examples: > SELECT array_repeat ( '123' , 2 ); [ \"123\" , \"123\" ] Since: 2.4.0","title":"array_repeat"},{"location":"appendix/appendix-b-spark/#array_sort","text":"array_sort(array) - Sorts the input array in ascending order. The elements of the input array must be orderable. Null elements will be placed at the end of the returned array. Examples: > SELECT array_sort ( array ( 'b' , 'd' , null , 'c' , 'a' )); [ \"a\" , \"b\" , \"c\" , \"d\" , null ] Since: 2.4.0","title":"array_sort"},{"location":"appendix/appendix-b-spark/#array_union","text":"array_union(array1, array2) - Returns an array of the elements in the union of array1 and array2, without duplicates. Examples: > SELECT array_union ( array ( 1 , 2 , 3 ), array ( 1 , 3 , 5 )); [ 1 , 2 , 3 , 5 ] Since: 2.4.0","title":"array_union"},{"location":"appendix/appendix-b-spark/#arrays_overlap","text":"arrays_overlap(a1, a2) - Returns true if a1 contains at least a non-null element present also in a2. If the arrays have no common element and they are both non-empty and either of them contains a null element null is returned, false otherwise. Examples: > SELECT arrays_overlap ( array ( 1 , 2 , 3 ), array ( 3 , 4 , 5 )); true Since: 2.4.0","title":"arrays_overlap"},{"location":"appendix/appendix-b-spark/#arrays_zip","text":"arrays_zip(a1, a2, ...) - Returns a merged array of structs in which the N-th struct contains all N-th values of input arrays. Examples: > SELECT arrays_zip ( array ( 1 , 2 , 3 ), array ( 2 , 3 , 4 )); [ { \"0\" : 1 , \"1\" : 2 } , { \"0\" : 2 , \"1\" : 3 } , { \"0\" : 3 , \"1\" : 4 } ] > SELECT arrays_zip ( array ( 1 , 2 ), array ( 2 , 3 ), array ( 3 , 4 )); [ { \"0\" : 1 , \"1\" : 2 , \"2\" : 3 } , { \"0\" : 2 , \"1\" : 3 , \"2\" : 4 } ] Since: 2.4.0","title":"arrays_zip"},{"location":"appendix/appendix-b-spark/#from_json","text":"from_json(jsonStr, schema[, options]) - Returns a struct value with the given jsonStr and schema. Examples: > SELECT from_json ( '{\"a\":1, \"b\":0.8}' , 'a INT, b DOUBLE' ); { \"a\" : 1 , \"b\" : 0 . 8 } > SELECT from_json ( '{\"time\":\"26/08/2015\"}' , 'time Timestamp' , map ( 'timestampFormat' , 'dd/MM/yyyy' )); { \"time\" : \"2015-08-26 00:00:00.0\" } Since: 2.2.0","title":"from_json"},{"location":"appendix/appendix-b-spark/#to_json","text":"to_json(expr[, options]) - Returns a json string with a given struct value Examples: > SELECT to_json ( named_struct ( 'a' , 1 , 'b' , 2 )); { \"a\" : 1 , \"b\" : 2 } > SELECT to_json ( named_struct ( 'time' , to_timestamp ( '2015-08-26' , 'yyyy-MM-dd' )), map ( 'timestampFormat' , 'dd/MM/yyyy' )); { \"time\" : \"26/08/2015\" } > SELECT to_json ( array ( named_struct ( 'a' , 1 , 'b' , 2 )); [ { \"a\" : 1 , \"b\" : 2 } ] > SELECT to_json ( map ( 'a' , named_struct ( 'b' , 1 ))); { \"a\" : { \"b\" : 1 }} > SELECT to_json ( map ( named_struct ( 'a' , 1 ), named_struct ( 'b' , 2 ))); { \"[1]\" : { \"b\" : 2 }} > SELECT to_json ( map ( 'a' , 1 )); { \"a\" : 1 } > SELECT to_json ( array (( map ( 'a' , 1 )))); [ { \"a\" : 1 } ] Since: 2.2.0","title":"to_json"},{"location":"appendix/appendix-b-spark/#reference","text":"Spark SQL, Built-in Functions","title":"Reference"},{"location":"appendix/appendix-c/","text":"\u9644\u5f55 C - Compare \u00b6 Compare 1 \u00b6 Compare 2 \u00b6 Reference \u00b6","title":"\u9644\u5f55 C - Compare"},{"location":"appendix/appendix-c/#c-compare","text":"","title":"\u9644\u5f55 C - Compare"},{"location":"appendix/appendix-c/#compare-1","text":"","title":"Compare 1"},{"location":"appendix/appendix-c/#compare-2","text":"","title":"Compare 2"},{"location":"appendix/appendix-c/#reference","text":"","title":"Reference"},{"location":"basis/compute/","text":"\u8ba1\u7b97\uff08Compute\uff09 \u00b6 \u8ba1\u7b97\u6a21\u5f0f\uff08Pattern\uff09 \u00b6 MR\u3001MRM\uff08Map\u3001Reduce\u3001Merge\uff09 \u53ef\u679a\u4e3e\u6027\uff08Ad hoc\u3001OLAP\uff09\u3001\u53ef\u52a0\u6027\uff08\u6279\u91cf\u3001\u589e\u91cf \uff09 \u4f18\u5316\uff08Optimization\uff09 \u00b6 \u4f18\u5316\uff08Optimization\uff09\uff1a\u7531\u7a0b\u5e8f\u9a71\u52a8\u4f18\u5316\uff1b \u8c03\u4f18\uff08Tuning\uff09\uff1a\u7531\u4eba\u5de5\u9a71\u52a8\u4f18\u5316 SQL\u5f15\u64ce \u00b6 \u57fa\u4e8e\u89c4\u5219\u7684\u4f18\u5316\uff08RBO\uff09\uff1a\u901a\u8fc7\u7f16\u7a0b\u3001\u5173\u7cfb\u4ee3\u6570\u7b49\u7406\u8bba\u8fdb\u884c\u5c40\u90e8\u4f18\u5316 \u57fa\u4e8e\u6210\u672c\u7684\u4f18\u5316\uff08CBO\uff09\uff1a\u57fa\u4e8e\u7edf\u8ba1\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u7b97\u6cd5\u3001\u589e\u5f3a\u5b66\u4e60\u8fdb\u884c\u4f18\u5316 \u57fa\u4e8e\u5386\u53f2\u7684\u4f18\u5316\uff08HBO\uff09\uff1a\u57fa\u4e8e\u5386\u53f2\u8fd0\u884c\u72b6\u6001\uff0c\u901a\u8fc7\u8fd0\u7b79\u89c4\u5212\u3001\u589e\u5f3a\u5b66\u4e60\u8fdb\u884c\u4f18\u5316 \u81ea\u9002\u5e94\u4f18\u5316\uff08Adapter\uff09\uff1a\u57fa\u4e8e\u8fd0\u884c\u65f6\u5ea6\u91cf\uff0c\u81ea\u9002\u5e94\u8c03\u6574 \u7ea6\u675f\u6761\u4ef6\uff08Constraint\uff09 \u00b6 Reference \u00b6","title":"\u8ba1\u7b97"},{"location":"basis/compute/#compute","text":"","title":"\u8ba1\u7b97\uff08Compute\uff09"},{"location":"basis/compute/#pattern","text":"MR\u3001MRM\uff08Map\u3001Reduce\u3001Merge\uff09 \u53ef\u679a\u4e3e\u6027\uff08Ad hoc\u3001OLAP\uff09\u3001\u53ef\u52a0\u6027\uff08\u6279\u91cf\u3001\u589e\u91cf \uff09","title":"\u8ba1\u7b97\u6a21\u5f0f\uff08Pattern\uff09"},{"location":"basis/compute/#optimization","text":"\u4f18\u5316\uff08Optimization\uff09\uff1a\u7531\u7a0b\u5e8f\u9a71\u52a8\u4f18\u5316\uff1b \u8c03\u4f18\uff08Tuning\uff09\uff1a\u7531\u4eba\u5de5\u9a71\u52a8\u4f18\u5316","title":"\u4f18\u5316\uff08Optimization\uff09"},{"location":"basis/compute/#sql","text":"\u57fa\u4e8e\u89c4\u5219\u7684\u4f18\u5316\uff08RBO\uff09\uff1a\u901a\u8fc7\u7f16\u7a0b\u3001\u5173\u7cfb\u4ee3\u6570\u7b49\u7406\u8bba\u8fdb\u884c\u5c40\u90e8\u4f18\u5316 \u57fa\u4e8e\u6210\u672c\u7684\u4f18\u5316\uff08CBO\uff09\uff1a\u57fa\u4e8e\u7edf\u8ba1\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u7b97\u6cd5\u3001\u589e\u5f3a\u5b66\u4e60\u8fdb\u884c\u4f18\u5316 \u57fa\u4e8e\u5386\u53f2\u7684\u4f18\u5316\uff08HBO\uff09\uff1a\u57fa\u4e8e\u5386\u53f2\u8fd0\u884c\u72b6\u6001\uff0c\u901a\u8fc7\u8fd0\u7b79\u89c4\u5212\u3001\u589e\u5f3a\u5b66\u4e60\u8fdb\u884c\u4f18\u5316 \u81ea\u9002\u5e94\u4f18\u5316\uff08Adapter\uff09\uff1a\u57fa\u4e8e\u8fd0\u884c\u65f6\u5ea6\u91cf\uff0c\u81ea\u9002\u5e94\u8c03\u6574","title":"SQL\u5f15\u64ce"},{"location":"basis/compute/#constraint","text":"","title":"\u7ea6\u675f\u6761\u4ef6\uff08Constraint\uff09"},{"location":"basis/compute/#reference","text":"","title":"Reference"},{"location":"basis/metrics/","text":"\u5ea6\u91cf\uff08Metrics\uff09 \u00b6 Reference \u00b6","title":"\u5ea6\u91cf"},{"location":"basis/metrics/#metrics","text":"","title":"\u5ea6\u91cf\uff08Metrics\uff09"},{"location":"basis/metrics/#reference","text":"","title":"Reference"},{"location":"basis/network/","text":"\u7f51\u7edc\uff08Network\uff09 \u00b6 \u901a\u4fe1\u673a\u5236 \u00b6 RPC\uff08Remote Procedure Call\uff09\uff1aProtocol Buffer\u3001Thrift\u3001Avro\uff08IDL\u3001Serialization\uff09 Message\uff1aQueue\u3001Pub-Sub\uff08Pull\u3001Push\uff09 Multi Broadcast\uff1aGossip\uff08Best Effort\u3001Anti-Entropy \u3001Rumor Mongering\uff09 Reference \u00b6 \u4f53\u7cfb\u5316\u8ba4\u8bc6RPC","title":"\u7f51\u7edc"},{"location":"basis/network/#network","text":"","title":"\u7f51\u7edc\uff08Network\uff09"},{"location":"basis/network/#_1","text":"RPC\uff08Remote Procedure Call\uff09\uff1aProtocol Buffer\u3001Thrift\u3001Avro\uff08IDL\u3001Serialization\uff09 Message\uff1aQueue\u3001Pub-Sub\uff08Pull\u3001Push\uff09 Multi Broadcast\uff1aGossip\uff08Best Effort\u3001Anti-Entropy \u3001Rumor Mongering\uff09","title":"\u901a\u4fe1\u673a\u5236"},{"location":"basis/network/#reference","text":"\u4f53\u7cfb\u5316\u8ba4\u8bc6RPC","title":"Reference"},{"location":"basis/schedule/","text":"\u8c03\u5ea6\uff08Schedule\uff09 \u00b6 \u8d44\u6e90\uff08Resource\uff09 \u00b6 \u8ba1\u7b97\uff08CPU\u3001GPU\uff09 I/O\uff08Memory\u3001Disk \u3001Network\u3001RAID\u3001HBA\uff09 \u5bb9\u5668\uff08Container\uff09 \u00b6 \u8d44\u6e90\u9694\u79bb\uff08Resource Isolation \uff09 \u751f\u547d\u5468\u671f\uff08Life Cycle\uff09 \u8d44\u6e90\u5206\u914d\uff08Allocation\uff09 \u00b6 \u5168\u91cf\uff08Gang \uff09 \u589e\u91cf\uff08Incremental \uff09 \u8c03\u5ea6\u7b56\u7565\uff08Strategy\uff09 \u00b6 FIFO Capacity Fair Delay DRF\uff08Domainant Reource Fair\uff09 \u8c03\u5ea6\u7b97\u6cd5\uff08Algorithm\uff09 \u00b6 First Fitness \u80cc\u5305\u95ee\u9898\uff1a\u8d2a\u5fc3\u7b97\u6cd5 \u89c4\u5212\u95ee\u9898\uff1a\u6574\u6570\u89c4\u5212 Graph Base\uff08Firmament\uff09 \u5f3a\u5316\u5b66\u4e60 \u8c03\u5ea6\u6a21\u578b\uff08Pattern\uff09 \u00b6 \u8d44\u6e90\uff08Yarn\u3001Mesos\u3001Kubernetes\uff09 \u4f5c\u4e1a\uff08Oozie\u3001Airflow\u3001Azkaban\uff09 \u4efb\u52a1\uff08Spark\u3001TEZ\u3001Presto\uff09 \u8c03\u5ea6\u67b6\u6784\uff08Architecture\uff09 \u00b6 \u96c6\u4e2d\u8c03\u5ea6\uff08Monolithic \uff09 \u4e24\u7ea7\u8c03\u5ea6\uff08Two Level \uff09 \u5171\u4eab\u72b6\u6001\u8c03\u5ea6\uff08Shared State \uff09 \u5168\u5206\u5e03\u5f0f\u8c03\u5ea6 \u6df7\u5408\u8c03\u5ea6 \u7ea6\u675f\u6761\u4ef6\uff08Constraint\uff09 \u00b6 \u8d44\u6e90\u5f02\u8d28\u6027\u3001\u8d1f\u8f7d\u5f02\u8d28\u6027\u3001\u4eb2\u548c\u4e0e\u53cd\u4eb2\u548c\u3001\u6570\u636e\u4f9d\u8d56\u3001\u6570\u636e\u672c\u5730\u6027\u3001\u8d44\u6e90\u5229\u7528\u7387\u3001\u8d44\u6e90\u9694\u79bb\u3001\u516c\u5e73\u6027\u3001\u4f18\u5148\u7ea7\u3001SLA\u3001\u9965\u997f\u4e0e\u6d3b\u9501\u3001\u5bb9\u9519 Reference\uff1a \u00b6 Scheduler Architectures Firmament: Fast, Centralized Cluster Scheduling at Scale","title":"\u8c03\u5ea6"},{"location":"basis/schedule/#schedule","text":"","title":"\u8c03\u5ea6\uff08Schedule\uff09"},{"location":"basis/schedule/#resource","text":"\u8ba1\u7b97\uff08CPU\u3001GPU\uff09 I/O\uff08Memory\u3001Disk \u3001Network\u3001RAID\u3001HBA\uff09","title":"\u8d44\u6e90\uff08Resource\uff09"},{"location":"basis/schedule/#container","text":"\u8d44\u6e90\u9694\u79bb\uff08Resource Isolation \uff09 \u751f\u547d\u5468\u671f\uff08Life Cycle\uff09","title":"\u5bb9\u5668\uff08Container\uff09"},{"location":"basis/schedule/#allocation","text":"\u5168\u91cf\uff08Gang \uff09 \u589e\u91cf\uff08Incremental \uff09","title":"\u8d44\u6e90\u5206\u914d\uff08Allocation\uff09"},{"location":"basis/schedule/#strategy","text":"FIFO Capacity Fair Delay DRF\uff08Domainant Reource Fair\uff09","title":"\u8c03\u5ea6\u7b56\u7565\uff08Strategy\uff09"},{"location":"basis/schedule/#algorithm","text":"First Fitness \u80cc\u5305\u95ee\u9898\uff1a\u8d2a\u5fc3\u7b97\u6cd5 \u89c4\u5212\u95ee\u9898\uff1a\u6574\u6570\u89c4\u5212 Graph Base\uff08Firmament\uff09 \u5f3a\u5316\u5b66\u4e60","title":"\u8c03\u5ea6\u7b97\u6cd5\uff08Algorithm\uff09"},{"location":"basis/schedule/#pattern","text":"\u8d44\u6e90\uff08Yarn\u3001Mesos\u3001Kubernetes\uff09 \u4f5c\u4e1a\uff08Oozie\u3001Airflow\u3001Azkaban\uff09 \u4efb\u52a1\uff08Spark\u3001TEZ\u3001Presto\uff09","title":"\u8c03\u5ea6\u6a21\u578b\uff08Pattern\uff09"},{"location":"basis/schedule/#architecture","text":"\u96c6\u4e2d\u8c03\u5ea6\uff08Monolithic \uff09 \u4e24\u7ea7\u8c03\u5ea6\uff08Two Level \uff09 \u5171\u4eab\u72b6\u6001\u8c03\u5ea6\uff08Shared State \uff09 \u5168\u5206\u5e03\u5f0f\u8c03\u5ea6 \u6df7\u5408\u8c03\u5ea6","title":"\u8c03\u5ea6\u67b6\u6784\uff08Architecture\uff09"},{"location":"basis/schedule/#constraint","text":"\u8d44\u6e90\u5f02\u8d28\u6027\u3001\u8d1f\u8f7d\u5f02\u8d28\u6027\u3001\u4eb2\u548c\u4e0e\u53cd\u4eb2\u548c\u3001\u6570\u636e\u4f9d\u8d56\u3001\u6570\u636e\u672c\u5730\u6027\u3001\u8d44\u6e90\u5229\u7528\u7387\u3001\u8d44\u6e90\u9694\u79bb\u3001\u516c\u5e73\u6027\u3001\u4f18\u5148\u7ea7\u3001SLA\u3001\u9965\u997f\u4e0e\u6d3b\u9501\u3001\u5bb9\u9519","title":"\u7ea6\u675f\u6761\u4ef6\uff08Constraint\uff09"},{"location":"basis/schedule/#reference","text":"Scheduler Architectures Firmament: Fast, Centralized Cluster Scheduling at Scale","title":"Reference\uff1a"},{"location":"basis/storage/","text":"\u5b58\u50a8\uff08Storage\uff09 \u00b6 \u5b58\u50a8\uff08Store\uff09 \u00b6 Disk() Memory(OnHeap/OffHeap) \u4f1a\u8bdd\uff08Session\uff09 \u00b6 Metastore Local Session Global Session \u6d17\u724c\uff08Shuffle\uff09 \u00b6 Read/Write Server/Client Pull/Push \u5b58\u50a8\u683c\u5f0f\uff08Storage Format\uff09 \u00b6 ORC Parquet CarbonData Other \u00b6 \u4f7f\u7528\u573a\u666f\uff1aAd-hoc\u3001OLAP\u3001OLTP\u3001HTAP \u5217\u5b58\u3001\u5411\u91cf\u5316\u3001\u51b7\u70ed\u5206\u7ea7 \u7a7a\u95f4\u6362\u65f6\u95f4\uff1a\u9884\u8ba1\u7b97\u3001\u7d22\u5f15 Reference \u00b6","title":"\u5b58\u50a8"},{"location":"basis/storage/#storage","text":"","title":"\u5b58\u50a8\uff08Storage\uff09"},{"location":"basis/storage/#store","text":"Disk() Memory(OnHeap/OffHeap)","title":"\u5b58\u50a8\uff08Store\uff09"},{"location":"basis/storage/#session","text":"Metastore Local Session Global Session","title":"\u4f1a\u8bdd\uff08Session\uff09"},{"location":"basis/storage/#shuffle","text":"Read/Write Server/Client Pull/Push","title":"\u6d17\u724c\uff08Shuffle\uff09"},{"location":"basis/storage/#storage-format","text":"ORC Parquet CarbonData","title":"\u5b58\u50a8\u683c\u5f0f\uff08Storage Format\uff09"},{"location":"basis/storage/#other","text":"\u4f7f\u7528\u573a\u666f\uff1aAd-hoc\u3001OLAP\u3001OLTP\u3001HTAP \u5217\u5b58\u3001\u5411\u91cf\u5316\u3001\u51b7\u70ed\u5206\u7ea7 \u7a7a\u95f4\u6362\u65f6\u95f4\uff1a\u9884\u8ba1\u7b97\u3001\u7d22\u5f15","title":"Other"},{"location":"basis/storage/#reference","text":"","title":"Reference"},{"location":"calcite/overview/","text":"TODO \u00b6 Reference \u00b6 Docs Github","title":"Calcite"},{"location":"calcite/overview/#todo","text":"","title":"TODO"},{"location":"calcite/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"carbondata/overview/","text":"Overview \u00b6 Apache CarbonData \u662f\u4e00\u79cd\u5728\u5927\u6570\u636e\u5e73\u53f0\u4e0a\u7528\u4e8e\u5feb\u901f\u5206\u6790\u7684\u5e26\u7d22\u5f15\u7684\u5217\u5f0f\u5b58\u50a8\u6570\u636e\u683c\u5f0f\u3002 Feature \u00b6 \u5217\u5f0f\u5b58\u50a8 \u591a\u7ea7\u7d22\u5f15\uff1aBTree\u3001MinMax \u5b57\u5178\u7f16\u7801 \u4e0b\u63a8\u4f18\u5316\uff1aFile\u3001Blocklet DDL\u3001DML\u3001Update\u3001Delete Partition\uff1acolumn\u3001hash,list,range DataMaps\uff1aPre-Aggregate\u3001Time Series\u3001Bloom filter\u3001Lucene\u3001MV (Materialized Views) \u6df1\u5ea6\u96c6\u6210Spark\uff0c\u652f\u6301Hive\u3001Presto Storage\uff1aS3\u3001HDFS\u3001Alluxio File Structure \u00b6 Directory \u00b6 Schema \u00b6 Format \u00b6 Header Blocklet Footer Other Index Dictionary Table Status Reference \u00b6 Docs Github","title":"CarbonData"},{"location":"carbondata/overview/#overview","text":"Apache CarbonData \u662f\u4e00\u79cd\u5728\u5927\u6570\u636e\u5e73\u53f0\u4e0a\u7528\u4e8e\u5feb\u901f\u5206\u6790\u7684\u5e26\u7d22\u5f15\u7684\u5217\u5f0f\u5b58\u50a8\u6570\u636e\u683c\u5f0f\u3002","title":"Overview"},{"location":"carbondata/overview/#feature","text":"\u5217\u5f0f\u5b58\u50a8 \u591a\u7ea7\u7d22\u5f15\uff1aBTree\u3001MinMax \u5b57\u5178\u7f16\u7801 \u4e0b\u63a8\u4f18\u5316\uff1aFile\u3001Blocklet DDL\u3001DML\u3001Update\u3001Delete Partition\uff1acolumn\u3001hash,list,range DataMaps\uff1aPre-Aggregate\u3001Time Series\u3001Bloom filter\u3001Lucene\u3001MV (Materialized Views) \u6df1\u5ea6\u96c6\u6210Spark\uff0c\u652f\u6301Hive\u3001Presto Storage\uff1aS3\u3001HDFS\u3001Alluxio","title":"Feature"},{"location":"carbondata/overview/#file-structure","text":"","title":"File Structure"},{"location":"carbondata/overview/#directory","text":"","title":"Directory"},{"location":"carbondata/overview/#schema","text":"","title":"Schema"},{"location":"carbondata/overview/#format","text":"Header Blocklet Footer Other Index Dictionary Table Status","title":"Format"},{"location":"carbondata/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"clickhouse/overview/","text":"TODO \u00b6 Reference \u00b6 ClickHouse Docs ClickHouse\u4e13\u4e1a\u4e2d\u6587\u793e\u533a ClickHouse\u4e2d\u56fd\u793e\u533a","title":"ClickHouse"},{"location":"clickhouse/overview/#todo","text":"","title":"TODO"},{"location":"clickhouse/overview/#reference","text":"ClickHouse Docs ClickHouse\u4e13\u4e1a\u4e2d\u6587\u793e\u533a ClickHouse\u4e2d\u56fd\u793e\u533a","title":"Reference"},{"location":"doris/overview/","text":"Overview \u00b6 Doris is a MPP-based interactive SQL data warehousing for reporting and analysis. FE\uff1aFrontend\uff0c\u5373 Doris \u7684\u524d\u7aef\u8282\u70b9\u3002\u4e3b\u8981\u8d1f\u8d23\u63a5\u6536\u548c\u8fd4\u56de\u5ba2\u6237\u7aef\u8bf7\u6c42\u3001\u5143\u6570\u636e\u4ee5\u53ca\u96c6\u7fa4\u7ba1\u7406\u3001\u67e5\u8be2\u8ba1\u5212\u751f\u6210\u7b49\u5de5\u4f5c\u3002 BE\uff1aBackend\uff0c\u5373 Doris \u7684\u540e\u7aef\u8282\u70b9\u3002\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5b58\u50a8\u4e0e\u7ba1\u7406\u3001\u67e5\u8be2\u8ba1\u5212\u6267\u884c\u7b49\u5de5\u4f5c\u3002 Reference \u00b6 Docs Wiki Github Palo - Baidu Doris development environment","title":"Doris"},{"location":"doris/overview/#overview","text":"Doris is a MPP-based interactive SQL data warehousing for reporting and analysis. FE\uff1aFrontend\uff0c\u5373 Doris \u7684\u524d\u7aef\u8282\u70b9\u3002\u4e3b\u8981\u8d1f\u8d23\u63a5\u6536\u548c\u8fd4\u56de\u5ba2\u6237\u7aef\u8bf7\u6c42\u3001\u5143\u6570\u636e\u4ee5\u53ca\u96c6\u7fa4\u7ba1\u7406\u3001\u67e5\u8be2\u8ba1\u5212\u751f\u6210\u7b49\u5de5\u4f5c\u3002 BE\uff1aBackend\uff0c\u5373 Doris \u7684\u540e\u7aef\u8282\u70b9\u3002\u4e3b\u8981\u8d1f\u8d23\u6570\u636e\u5b58\u50a8\u4e0e\u7ba1\u7406\u3001\u67e5\u8be2\u8ba1\u5212\u6267\u884c\u7b49\u5de5\u4f5c\u3002","title":"Overview"},{"location":"doris/overview/#reference","text":"Docs Wiki Github Palo - Baidu Doris development environment","title":"Reference"},{"location":"druid/overview/","text":"Overview \u00b6 Druid is an open source distributed data store. Druid\u2019s core design combines ideas from OLAP/analytic databases, timeseries databases, and search systems to create a unified system for a broad range of use cases. Druid merges key characteristics of each of the 3 systems into its ingestion layer, storage format, querying layer, and core architecture. Key Features \u00b6 Column-oriented storage Druid stores and compresses each column individually, and only needs to read the ones needed for a particular query, which supports fast scans, rankings, and groupBys. Native search indexes Druid creates inverted indexes for string values for fast search and filter. Streaming and batch ingest Out-of-the-box connectors for Apache Kafka, HDFS, AWS S3, stream processors, and more. Flexible schemas Druid gracefully handles evolving schemas and nested data. Time-optimized partitioning Druid intelligently partitions data based on time and time-based queries are significantly faster than traditional databases. SQL support In addition to its native JSON based language, Druid speaks SQL over either HTTP or JDBC. Horizontal scalability Druid has been used in production to ingest millions of events/sec, retain years of data, and provide sub-second queries. Easy operation Scale up or down by just adding or removing servers, and Druid automatically rebalances. Fault-tolerant architecture routes around server failures. Architecture \u00b6 \u5386\u53f2\u8282\u70b9\uff08Historical Node\uff09 \uff1a\u5386\u53f2\u6570\u636e Segment \u7684\u52a0\u8f7d\u548c\u67e5\u8be2 \u4e2d\u95f4\u7ba1\u7406\u8282\u70b9\uff08MiddleManager Node\uff09\uff1a\u5b9e\u65f6\u53ca\u79bb\u7ebf\u6570\u636e\u6444\u5165\uff0c\u751f\u6210 Segment \u534f\u8c03\u8282\u70b9\uff08Coordinator Node\uff09\uff1a\u5bf9\u5386\u53f2\u670d\u52a1\u6570\u636e\u8d1f\u8f7d\u5747\u8861 \u63a7\u5236\u8282\u70b9\uff08Overlord Node\uff09\uff1a\u63a7\u5236\u6570\u636e\u6444\u5165\u5206\u914d\uff0c\u534f\u8c03\u53d1\u5e03 Segment \u67e5\u8be2\u8282\u70b9\uff08Broker Node\uff09\uff1a\u5bf9\u5916\u63d0\u4f9b\u67e5\u8be2\u670d\u52a1 \u8def\u7531\u8282\u70b9\uff08Router Node\uff09\uff1a\u7edf\u4e00API\u7f51\u5173 \u00b6 Reference \u00b6 Docs Github","title":"Druid"},{"location":"druid/overview/#overview","text":"Druid is an open source distributed data store. Druid\u2019s core design combines ideas from OLAP/analytic databases, timeseries databases, and search systems to create a unified system for a broad range of use cases. Druid merges key characteristics of each of the 3 systems into its ingestion layer, storage format, querying layer, and core architecture.","title":"Overview"},{"location":"druid/overview/#key-features","text":"Column-oriented storage Druid stores and compresses each column individually, and only needs to read the ones needed for a particular query, which supports fast scans, rankings, and groupBys. Native search indexes Druid creates inverted indexes for string values for fast search and filter. Streaming and batch ingest Out-of-the-box connectors for Apache Kafka, HDFS, AWS S3, stream processors, and more. Flexible schemas Druid gracefully handles evolving schemas and nested data. Time-optimized partitioning Druid intelligently partitions data based on time and time-based queries are significantly faster than traditional databases. SQL support In addition to its native JSON based language, Druid speaks SQL over either HTTP or JDBC. Horizontal scalability Druid has been used in production to ingest millions of events/sec, retain years of data, and provide sub-second queries. Easy operation Scale up or down by just adding or removing servers, and Druid automatically rebalances. Fault-tolerant architecture routes around server failures.","title":"Key Features"},{"location":"druid/overview/#architecture","text":"\u5386\u53f2\u8282\u70b9\uff08Historical Node\uff09 \uff1a\u5386\u53f2\u6570\u636e Segment \u7684\u52a0\u8f7d\u548c\u67e5\u8be2 \u4e2d\u95f4\u7ba1\u7406\u8282\u70b9\uff08MiddleManager Node\uff09\uff1a\u5b9e\u65f6\u53ca\u79bb\u7ebf\u6570\u636e\u6444\u5165\uff0c\u751f\u6210 Segment \u534f\u8c03\u8282\u70b9\uff08Coordinator Node\uff09\uff1a\u5bf9\u5386\u53f2\u670d\u52a1\u6570\u636e\u8d1f\u8f7d\u5747\u8861 \u63a7\u5236\u8282\u70b9\uff08Overlord Node\uff09\uff1a\u63a7\u5236\u6570\u636e\u6444\u5165\u5206\u914d\uff0c\u534f\u8c03\u53d1\u5e03 Segment \u67e5\u8be2\u8282\u70b9\uff08Broker Node\uff09\uff1a\u5bf9\u5916\u63d0\u4f9b\u67e5\u8be2\u670d\u52a1 \u8def\u7531\u8282\u70b9\uff08Router Node\uff09\uff1a\u7edf\u4e00API\u7f51\u5173","title":"Architecture"},{"location":"druid/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"hive/overview/","text":"TODO \u00b6 Reference \u00b6 Docs Github","title":"TODO"},{"location":"hive/overview/#todo","text":"","title":"TODO"},{"location":"hive/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"impala/overview/","text":"TODO \u00b6 Reference \u00b6 Docs Github","title":"Impala"},{"location":"impala/overview/#todo","text":"","title":"TODO"},{"location":"impala/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"kylin/overview/","text":"Overview \u00b6 Apache Kylin\u2122\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u5206\u5e03\u5f0f\u5206\u6790\u5f15\u64ce\uff0c\u63d0\u4f9bHadoop/Spark\u4e4b\u4e0a\u7684SQL\u67e5\u8be2\u63a5\u53e3\u53ca\u591a\u7ef4\u5206\u6790\uff08OLAP\uff09\u80fd\u529b\u4ee5\u652f\u6301\u8d85\u5927\u89c4\u6a21\u6570\u636e\uff0c\u6700\u521d\u7531eBay Inc. \u5f00\u53d1\u5e76\u8d21\u732e\u81f3\u5f00\u6e90\u793e\u533a\u3002\u5b83\u80fd\u5728\u4e9a\u79d2\u5185\u67e5\u8be2\u5de8\u5927\u7684Hive\u8868\u3002 Reference \u00b6 Docs Github","title":"Kylin"},{"location":"kylin/overview/#overview","text":"Apache Kylin\u2122\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u5206\u5e03\u5f0f\u5206\u6790\u5f15\u64ce\uff0c\u63d0\u4f9bHadoop/Spark\u4e4b\u4e0a\u7684SQL\u67e5\u8be2\u63a5\u53e3\u53ca\u591a\u7ef4\u5206\u6790\uff08OLAP\uff09\u80fd\u529b\u4ee5\u652f\u6301\u8d85\u5927\u89c4\u6a21\u6570\u636e\uff0c\u6700\u521d\u7531eBay Inc. \u5f00\u53d1\u5e76\u8d21\u732e\u81f3\u5f00\u6e90\u793e\u533a\u3002\u5b83\u80fd\u5728\u4e9a\u79d2\u5185\u67e5\u8be2\u5de8\u5927\u7684Hive\u8868\u3002","title":"Overview"},{"location":"kylin/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"orc/overview/","text":"Overview \u00b6 ORC\uff08Optimized Row Columnar\uff09\u4f7f\u7528\u7279\u5b9a\u7684 Readers \u548c Writers \uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u6570\u636e\u538b\u7f29\uff0c\u5982\u5b57\u5178\u7f16\u7801\uff0c\u4f4d\u7ec4\u88c5\uff0c\u5dee\u5206\u7f16\u7801\u548c\u6e38\u7a0b\u7f16\u7801\uff0c\u800c\u663e\u8457\u51cf\u5c0f\u7684\u751f\u6210\u6587\u4ef6\uff0c\u4e5f\u53ef\u4ee5\u914d\u5408zlib\u3001Snappy\u4f7f\u7528\u3002ORC \u652f\u6301\u6295\u5f71\u3001\u4e0b\u63a8\u3001\u5411\u91cf\u5316\u3001\u8f7b\u91cf\u7ea7\u7d22\u5f15\u7b49\u7279\u6027\u3002 File Tail \u00b6 Postscript Footer Stripe Information Type Information Column Statistics User Metadata File Metadata Compression \u00b6 Run Length Encoding \u00b6 Base 128 Varint Byte Run Length Encoding Boolean Run Length Encoding Integer Run Length Encoding, version 1 Integer Run Length Encoding, version 2 Short Repeat - used for short sequences with repeated values Direct - used for random sequences with a fixed bit width Patched Base - used for random sequences with a variable bit width Delta - used for monotonically increasing or decreasing sequences Stripes \u00b6 Column Encodings \u00b6 SmallInt, Int, and BigInt Columns Float and Double Columns String, Char, and VarChar Columns Boolean Columns TinyInt Columns Binary Columns Decimal Columns Date Columns Timestamp Columns Struct Columns List Columns Map Columns Union Columns Indexes \u00b6 Row Group Index Bloom Filter Index Reference \u00b6 Docs Github ORC Specification orc_proto.proto","title":"ORC"},{"location":"orc/overview/#overview","text":"ORC\uff08Optimized Row Columnar\uff09\u4f7f\u7528\u7279\u5b9a\u7684 Readers \u548c Writers \uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u6570\u636e\u538b\u7f29\uff0c\u5982\u5b57\u5178\u7f16\u7801\uff0c\u4f4d\u7ec4\u88c5\uff0c\u5dee\u5206\u7f16\u7801\u548c\u6e38\u7a0b\u7f16\u7801\uff0c\u800c\u663e\u8457\u51cf\u5c0f\u7684\u751f\u6210\u6587\u4ef6\uff0c\u4e5f\u53ef\u4ee5\u914d\u5408zlib\u3001Snappy\u4f7f\u7528\u3002ORC \u652f\u6301\u6295\u5f71\u3001\u4e0b\u63a8\u3001\u5411\u91cf\u5316\u3001\u8f7b\u91cf\u7ea7\u7d22\u5f15\u7b49\u7279\u6027\u3002","title":"Overview"},{"location":"orc/overview/#file-tail","text":"Postscript Footer Stripe Information Type Information Column Statistics User Metadata File Metadata","title":"File Tail"},{"location":"orc/overview/#compression","text":"","title":"Compression"},{"location":"orc/overview/#run-length-encoding","text":"Base 128 Varint Byte Run Length Encoding Boolean Run Length Encoding Integer Run Length Encoding, version 1 Integer Run Length Encoding, version 2 Short Repeat - used for short sequences with repeated values Direct - used for random sequences with a fixed bit width Patched Base - used for random sequences with a variable bit width Delta - used for monotonically increasing or decreasing sequences","title":"Run Length Encoding"},{"location":"orc/overview/#stripes","text":"","title":"Stripes"},{"location":"orc/overview/#column-encodings","text":"SmallInt, Int, and BigInt Columns Float and Double Columns String, Char, and VarChar Columns Boolean Columns TinyInt Columns Binary Columns Decimal Columns Date Columns Timestamp Columns Struct Columns List Columns Map Columns Union Columns","title":"Column Encodings"},{"location":"orc/overview/#indexes","text":"Row Group Index Bloom Filter Index","title":"Indexes"},{"location":"orc/overview/#reference","text":"Docs Github ORC Specification orc_proto.proto","title":"Reference"},{"location":"parquet/overview/","text":"TODO \u00b6 Reference \u00b6 Docs Github","title":"Parquet"},{"location":"parquet/overview/#todo","text":"","title":"TODO"},{"location":"parquet/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"practice/projects-and-articles/","text":"Projects & Articles \u00b6 Projects \u00b6 Spark SQL : Spark SQL is Apache Spark's module for working with structured data. Hive : The Apache Hive \u2122 data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive. Presto : Distributed SQL Query Engine for Big Data. Impala - The open source, native analytic database for Apache Hadoop. Druid - A high performance real-time analytics database. Kylin - An open source Distributed Analytics Engine designed to provide SQL interface and multi-dimensional analysis (OLAP) on Hadoop/Spark supporting extremely large datasets. HAWQ - Apache Hadoop Native SQL. Advanced, MPP, elastic query engine and analytic database for enterprises. Drill - Schema-free SQL Query Engine for Hadoop, NoSQL and Cloud Storage TiDB - \u5f00\u6e90\u5206\u5e03\u5f0f\u5173\u7cfb\u578b\u6570\u636e\u5e93 ClickHouse - An open source column-oriented database management system capable of real time generation of analytical data reports using SQL queries. SnappyData - The Apache Spark Database. Doris(Palo) - A MPP-based interactive SQL data warehousing for reporting and analysis. Antlr4 - ANother Tool for Language Recognition. Calcite - Dynamic data management framework. Papers \u00b6 Spark \u00b6 Spark SQL: Relational Data Processing in Spark Learning to Optimize Join Queries With Deep Reinforcement Learning SIGMOD \u00b6 Column-stores vs. row-stores: how different are they really? Articles \u00b6 Resources \u00b6 Spark \u00b6 Spark \u8bba\u6587\uff08\u5927\u578b\u96c6\u7fa4\u4e0a\u4e00\u79cd\u5feb\u901f\u548c\u901a\u7528\u6570\u636e\u5904\u7406\u67b6\u6784\uff09 Spark Internals Spark Internals\uff08\u4e2d\u6587\uff09 Spark\u6280\u672f\u5185\u5e55 Spark SQL\u6e90\u7801\u5206\u6790\u7cfb\u5217 Coolplay Spark\uff1a\u9177\u73a9 Spark: Spark \u6e90\u4ee3\u7801\u89e3\u6790\u3001Spark \u7c7b\u5e93\u7b49 Spark Graphx \u7684\u539f\u7406\u53ca\u76f8\u5173\u64cd\u4f5c\u7684\u6e90\u7801\u89e3\u6790 Spark ML Source Analysis\uff1aspark ml \u7b97\u6cd5\u539f\u7406\u5256\u6790\u4ee5\u53ca\u5177\u4f53\u7684\u6e90\u7801\u5b9e\u73b0\u5206\u6790 Spark \u7f16\u7a0b\u6307\u5357\u7b80\u4f53\u4e2d\u6587\u7248 Spark \u6027\u80fd\u8c03\u4f18\u603b\u7ed3 Reference \u00b6","title":"\u9879\u76ee\u4e0e\u6587\u7ae0"},{"location":"practice/projects-and-articles/#projects-articles","text":"","title":"Projects &amp; Articles"},{"location":"practice/projects-and-articles/#projects","text":"Spark SQL : Spark SQL is Apache Spark's module for working with structured data. Hive : The Apache Hive \u2122 data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive. Presto : Distributed SQL Query Engine for Big Data. Impala - The open source, native analytic database for Apache Hadoop. Druid - A high performance real-time analytics database. Kylin - An open source Distributed Analytics Engine designed to provide SQL interface and multi-dimensional analysis (OLAP) on Hadoop/Spark supporting extremely large datasets. HAWQ - Apache Hadoop Native SQL. Advanced, MPP, elastic query engine and analytic database for enterprises. Drill - Schema-free SQL Query Engine for Hadoop, NoSQL and Cloud Storage TiDB - \u5f00\u6e90\u5206\u5e03\u5f0f\u5173\u7cfb\u578b\u6570\u636e\u5e93 ClickHouse - An open source column-oriented database management system capable of real time generation of analytical data reports using SQL queries. SnappyData - The Apache Spark Database. Doris(Palo) - A MPP-based interactive SQL data warehousing for reporting and analysis. Antlr4 - ANother Tool for Language Recognition. Calcite - Dynamic data management framework.","title":"Projects"},{"location":"practice/projects-and-articles/#papers","text":"","title":"Papers"},{"location":"practice/projects-and-articles/#spark","text":"Spark SQL: Relational Data Processing in Spark Learning to Optimize Join Queries With Deep Reinforcement Learning","title":"Spark"},{"location":"practice/projects-and-articles/#sigmod","text":"Column-stores vs. row-stores: how different are they really?","title":"SIGMOD"},{"location":"practice/projects-and-articles/#articles","text":"","title":"Articles"},{"location":"practice/projects-and-articles/#resources","text":"","title":"Resources"},{"location":"practice/projects-and-articles/#spark_1","text":"Spark \u8bba\u6587\uff08\u5927\u578b\u96c6\u7fa4\u4e0a\u4e00\u79cd\u5feb\u901f\u548c\u901a\u7528\u6570\u636e\u5904\u7406\u67b6\u6784\uff09 Spark Internals Spark Internals\uff08\u4e2d\u6587\uff09 Spark\u6280\u672f\u5185\u5e55 Spark SQL\u6e90\u7801\u5206\u6790\u7cfb\u5217 Coolplay Spark\uff1a\u9177\u73a9 Spark: Spark \u6e90\u4ee3\u7801\u89e3\u6790\u3001Spark \u7c7b\u5e93\u7b49 Spark Graphx \u7684\u539f\u7406\u53ca\u76f8\u5173\u64cd\u4f5c\u7684\u6e90\u7801\u89e3\u6790 Spark ML Source Analysis\uff1aspark ml \u7b97\u6cd5\u539f\u7406\u5256\u6790\u4ee5\u53ca\u5177\u4f53\u7684\u6e90\u7801\u5b9e\u73b0\u5206\u6790 Spark \u7f16\u7a0b\u6307\u5357\u7b80\u4f53\u4e2d\u6587\u7248 Spark \u6027\u80fd\u8c03\u4f18\u603b\u7ed3","title":"Spark"},{"location":"practice/projects-and-articles/#reference","text":"","title":"Reference"},{"location":"practice/tuning-and-case/","text":"Tuning & Case \u00b6 Tuning \u00b6 Configuration \u00b6 Design & Program \u00b6 Dependency & Boundary \u00b6 Case \u00b6 Case 1 \u00b6 select * from girls where age between 18 and 24 and boyfriend = 'no' Reference \u00b6 Tuning Spark","title":"\u8c03\u4f18\u4e0e\u6848\u4f8b"},{"location":"practice/tuning-and-case/#tuning-case","text":"","title":"Tuning &amp; Case"},{"location":"practice/tuning-and-case/#tuning","text":"","title":"Tuning"},{"location":"practice/tuning-and-case/#configuration","text":"","title":"Configuration"},{"location":"practice/tuning-and-case/#design-program","text":"","title":"Design &amp; Program"},{"location":"practice/tuning-and-case/#dependency-boundary","text":"","title":"Dependency &amp; Boundary"},{"location":"practice/tuning-and-case/#case","text":"","title":"Case"},{"location":"practice/tuning-and-case/#case-1","text":"select * from girls where age between 18 and 24 and boyfriend = 'no'","title":"Case 1"},{"location":"practice/tuning-and-case/#reference","text":"Tuning Spark","title":"Reference"},{"location":"practice/work-and-practices/","text":"Work & Practices \u00b6 ETL & DW \u00b6 Tuning \u00b6 Spark \u00b6 Spark \u6027\u80fd\u8c03\u4f18\u603b\u7ed3 Optimizer \u00b6 RBO(Rule) CBO(Cost) HBO(History) ABO(Adaptive) Data Governance\uff08Table & Column -> Lineage & Impact -> Data Graph\uff09 \u00b6 Atlas Sentry WhereHows Spline Performance\uff08Metrics\u3001Heuristics\uff09 \u00b6 Dr. Elephant Sparklint SparkOscope Sparklens SparkMeasure DRIVEN Reference \u00b6","title":"\u5de5\u4f5c\u4e0e\u5b9e\u8df5"},{"location":"practice/work-and-practices/#work-practices","text":"","title":"Work &amp; Practices"},{"location":"practice/work-and-practices/#etl-dw","text":"","title":"ETL &amp; DW"},{"location":"practice/work-and-practices/#tuning","text":"","title":"Tuning"},{"location":"practice/work-and-practices/#spark","text":"Spark \u6027\u80fd\u8c03\u4f18\u603b\u7ed3","title":"Spark"},{"location":"practice/work-and-practices/#optimizer","text":"RBO(Rule) CBO(Cost) HBO(History) ABO(Adaptive)","title":"Optimizer"},{"location":"practice/work-and-practices/#data-governancetable-column-lineage-impact-data-graph","text":"Atlas Sentry WhereHows Spline","title":"Data Governance\uff08Table &amp; Column -&gt; Lineage &amp; Impact -&gt; Data Graph\uff09"},{"location":"practice/work-and-practices/#performancemetricsheuristics","text":"Dr. Elephant Sparklint SparkOscope Sparklens SparkMeasure DRIVEN","title":"Performance\uff08Metrics\u3001Heuristics\uff09"},{"location":"practice/work-and-practices/#reference","text":"","title":"Reference"},{"location":"presto/overview/","text":"Overview \u00b6 Reference \u00b6 Docs Github","title":"TODO"},{"location":"presto/overview/#overview","text":"","title":"Overview"},{"location":"presto/overview/#reference","text":"Docs Github","title":"Reference"},{"location":"retreat/knowledge/","text":"\u77e5\u8bc6\u9886\u57df \u00b6 Database \u00b6 \u5b58\u50a8\uff1a\u884c\u3001\u5217 \u7d22\u5f15\uff1aB+Tree\u3001MergeTree\u3001\u5012\u6392\u7d22\u5f15\u3001\u4f4d\u56fe \u67e5\u8be2\uff1a\u4f1a\u8bdd \u4f18\u5316 \u6545\u969c \u5e76\u53d1 \u4e8b\u52a1 \u7ba1\u7406 \u5206\u5e03\u5f0f Knowledge \u00b6 \u64cd\u4f5c\u7cfb\u7edf\uff1a\u8fdb\u7a0b\u3001\u8c03\u5ea6\u3001\u5185\u5b58\u3001\u6587\u4ef6\u3001IO \u7f51\u7edc\uff1aTCP\u3001RPC\u3001Akka\u3001Netty \u6570\u636e\u5e93\uff1a\u5173\u7cfb\u6a21\u578b\u3001SQL\u3001\u4e8b\u52a1\u3001\u7d22\u5f15 \u6570\u636e\u7ed3\u6784\u4e0e\u7b97\u6cd5\uff1aRaft\u3001Hash\u3001Probability\u3001Heuristic Java/Scala\uff1aJVM\u3001JMM\u3001GC\u3001JIT \u5206\u5e03\u5f0f\uff1a\u5b58\u50a8\u3001\u8ba1\u7b97\u3001\u8c03\u5ea6\u3001\u7ba1\u7406\u3001\u65e5\u5fd7 Book \u00b6 Reference\uff1a \u00b6 \u6570\u636e\u5e93\u5185\u6838\u6708\u62a5 Computer Science Learning Notes OI Wiki \u5206\u5e03\u5f0f\u7cfb\u7edf \u8bfb\u540e\u611f \u5206\u5e03\u5f0f\u7cfb\u7edf\u5de5\u7a0b\u5b9e\u8df5","title":"\u77e5\u8bc6\u9886\u57df"},{"location":"retreat/knowledge/#_1","text":"","title":"\u77e5\u8bc6\u9886\u57df"},{"location":"retreat/knowledge/#database","text":"\u5b58\u50a8\uff1a\u884c\u3001\u5217 \u7d22\u5f15\uff1aB+Tree\u3001MergeTree\u3001\u5012\u6392\u7d22\u5f15\u3001\u4f4d\u56fe \u67e5\u8be2\uff1a\u4f1a\u8bdd \u4f18\u5316 \u6545\u969c \u5e76\u53d1 \u4e8b\u52a1 \u7ba1\u7406 \u5206\u5e03\u5f0f","title":"Database"},{"location":"retreat/knowledge/#knowledge","text":"\u64cd\u4f5c\u7cfb\u7edf\uff1a\u8fdb\u7a0b\u3001\u8c03\u5ea6\u3001\u5185\u5b58\u3001\u6587\u4ef6\u3001IO \u7f51\u7edc\uff1aTCP\u3001RPC\u3001Akka\u3001Netty \u6570\u636e\u5e93\uff1a\u5173\u7cfb\u6a21\u578b\u3001SQL\u3001\u4e8b\u52a1\u3001\u7d22\u5f15 \u6570\u636e\u7ed3\u6784\u4e0e\u7b97\u6cd5\uff1aRaft\u3001Hash\u3001Probability\u3001Heuristic Java/Scala\uff1aJVM\u3001JMM\u3001GC\u3001JIT \u5206\u5e03\u5f0f\uff1a\u5b58\u50a8\u3001\u8ba1\u7b97\u3001\u8c03\u5ea6\u3001\u7ba1\u7406\u3001\u65e5\u5fd7","title":"Knowledge"},{"location":"retreat/knowledge/#book","text":"","title":"Book"},{"location":"retreat/knowledge/#reference","text":"\u6570\u636e\u5e93\u5185\u6838\u6708\u62a5 Computer Science Learning Notes OI Wiki \u5206\u5e03\u5f0f\u7cfb\u7edf \u8bfb\u540e\u611f \u5206\u5e03\u5f0f\u7cfb\u7edf\u5de5\u7a0b\u5b9e\u8df5","title":"Reference\uff1a"},{"location":"retreat/relational-algebra/","text":"\u5173\u7cfb\u4ee3\u6570\uff08Relational Algebra\uff09 \u00b6 \u57fa\u4e8e\u8fd0\u7b97\u5bf9\u8c61\u7684\u6570\u91cf\uff1a\u4e00\u5143\u8fd0\u7b97\uff0c\u4e8c\u5143\u8fd0\u7b97 \u57fa\u7840\u8fd0\u7b97\uff08\u57fa\u7840\uff09 \u00b6 \u903b\u8f91\u8fd0\u7b97 \uff1a\u6216\uff08or < \u2228 >\uff09\u3001\u4e0e\uff08and < \u2227 >\uff09\u3001\u975e\uff08not < \u00ac >\uff09 \u6bd4\u8f83\u8fd0\u7b97 \uff1a\u5c0f\u4e8e\uff08<\uff09\u3001\u5c0f\u4e8e\u7b49\u4e8e\uff08<=\uff09\u3001\u5927\u4e8e\uff08>\uff09\u3001\u5927\u4e8e\u7b49\u4e8e\uff08>=\uff09\u3001\u7b49\u4e8e\uff08=\uff09\u3001\u4e0d\u7b49\u4e8e\uff08<>\uff09 \u96c6\u5408\u8fd0\u7b97 \uff1a\u4ea4\uff08\u2229\uff09\u3001\u5e76\uff08\u222a\uff09\u3001\u5dee\uff08\u2212\uff09\u3001\u7b1b\u5361\u5c14\u79ef\uff08\u00d7\uff09 \u5173\u7cfb\u8fd0\u7b97\uff08\u91cd\u70b9\uff09 \u00b6 \u5173\u7cfb\u8fd0\u7b97 \uff1a\u9009\u62e9\uff08Selection < \u03c3 >\uff09\u3001\u6295\u5f71\uff08Projection < \u03c0 > \uff09\u3001\u8fde\u63a5\uff08Join < \u22c8 >\uff09\u3001\u9664\uff08\u00f7\uff09\u3001\u91cd\u547d\u540d\uff08\u03c1\uff09 \u805a\u96c6\u8fd0\u7b97\uff08\u6269\u5c55\uff09 \u00b6 \u805a\u96c6\u8fd0\u7b97 \uff1a\u6c42\u548c\uff08sum\uff09\u3001\u8ba1\u6570\uff08count\uff09\u3001\u5747\u503c\uff08avg\uff09\u3001\u6700\u5927\u503c\uff08max\uff09\u3001\u6700\u5c0f\u503c\uff08min\uff09 \u00b7 \u00b7 \u00b7 Reference \u00b6 \u5173\u7cfb\u4ee3\u6570","title":"\u5173\u7cfb\u4ee3\u6570"},{"location":"retreat/relational-algebra/#relational-algebra","text":"\u57fa\u4e8e\u8fd0\u7b97\u5bf9\u8c61\u7684\u6570\u91cf\uff1a\u4e00\u5143\u8fd0\u7b97\uff0c\u4e8c\u5143\u8fd0\u7b97","title":"\u5173\u7cfb\u4ee3\u6570\uff08Relational Algebra\uff09"},{"location":"retreat/relational-algebra/#_1","text":"\u903b\u8f91\u8fd0\u7b97 \uff1a\u6216\uff08or < \u2228 >\uff09\u3001\u4e0e\uff08and < \u2227 >\uff09\u3001\u975e\uff08not < \u00ac >\uff09 \u6bd4\u8f83\u8fd0\u7b97 \uff1a\u5c0f\u4e8e\uff08<\uff09\u3001\u5c0f\u4e8e\u7b49\u4e8e\uff08<=\uff09\u3001\u5927\u4e8e\uff08>\uff09\u3001\u5927\u4e8e\u7b49\u4e8e\uff08>=\uff09\u3001\u7b49\u4e8e\uff08=\uff09\u3001\u4e0d\u7b49\u4e8e\uff08<>\uff09 \u96c6\u5408\u8fd0\u7b97 \uff1a\u4ea4\uff08\u2229\uff09\u3001\u5e76\uff08\u222a\uff09\u3001\u5dee\uff08\u2212\uff09\u3001\u7b1b\u5361\u5c14\u79ef\uff08\u00d7\uff09","title":"\u57fa\u7840\u8fd0\u7b97\uff08\u57fa\u7840\uff09"},{"location":"retreat/relational-algebra/#_2","text":"\u5173\u7cfb\u8fd0\u7b97 \uff1a\u9009\u62e9\uff08Selection < \u03c3 >\uff09\u3001\u6295\u5f71\uff08Projection < \u03c0 > \uff09\u3001\u8fde\u63a5\uff08Join < \u22c8 >\uff09\u3001\u9664\uff08\u00f7\uff09\u3001\u91cd\u547d\u540d\uff08\u03c1\uff09","title":"\u5173\u7cfb\u8fd0\u7b97\uff08\u91cd\u70b9\uff09"},{"location":"retreat/relational-algebra/#_3","text":"\u805a\u96c6\u8fd0\u7b97 \uff1a\u6c42\u548c\uff08sum\uff09\u3001\u8ba1\u6570\uff08count\uff09\u3001\u5747\u503c\uff08avg\uff09\u3001\u6700\u5927\u503c\uff08max\uff09\u3001\u6700\u5c0f\u503c\uff08min\uff09 \u00b7 \u00b7 \u00b7","title":"\u805a\u96c6\u8fd0\u7b97\uff08\u6269\u5c55\uff09"},{"location":"retreat/relational-algebra/#reference","text":"\u5173\u7cfb\u4ee3\u6570","title":"Reference"},{"location":"retreat/relational-model/","text":"\u5173\u7cfb\u6a21\u578b\uff08Relational Model\uff09 \u00b6 \u5173\u7cfb\u6a21\u578b \uff08Relational Model\uff09\uff1a\u57fa\u4e8e \u8c13\u8bcd\u903b\u8f91 \u548c \u96c6\u5408\u8bba \u7684\u4e00\u79cd\u6570\u636e\u6a21\u578b\u3002 \u5173\u7cfb\u6a21\u578b \u7684\u57fa\u672c\u5047\u5b9a\u662f\u6240\u6709\u6570\u636e\u90fd\u8868\u793a\u4e3a\u6570\u5b66\u4e0a\u7684 \u5173\u7cfb \uff0c\u5c31\u662f\u8bf4 n \u4e2a\u96c6\u5408\u7684\u7b1b\u5361\u513f\u79ef\u7684\u4e00\u4e2a\u5b50\u96c6\uff1b\u6709\u5173\u8fd9\u79cd\u6570\u636e\u7684\u63a8\u7406\u901a\u8fc7\u4e8c\u503c\uff08\u5c31\u662f\u8bf4\u6ca1\u6709 NULL \uff09\u7684 \u8c13\u8bcd\u903b\u8f91 \u6765\u8fdb\u884c\uff0c\u8fd9\u610f\u5473\u7740\u5bf9\u6bcf\u4e2a\u547d\u9898\u90fd\u6709\u4e24\u79cd\u53ef\u80fd\u7684\u8ce6\u503c\uff1a\u8981\u4e48\u662f\u771f\u8981\u4e48\u662f\u5047\u3002 \u6570\u636e\u901a\u8fc7 \u5173\u7cfb\u6f14\u7b97 \u548c \u5173\u7cfb\u4ee3\u6570 \u65b9\u5f0f\u8fdb\u884c\u64cd\u4f5c\u3002 \u5173\u7cfb\u6f14\u7b97\uff08\u57fa\u4e8e \u8c13\u8bcd\u903b\u8f91 \uff09 \u5143\u7ec4\u5173\u7cfb\u6f14\u7b97\uff08\u884c\uff09 \u57df\u5173\u7cfb\u6f14\u7b97\uff08\u5217\uff09 \u5173\u7cfb\u4ee3\u6570\uff08\u57fa\u4e8e \u96c6\u5408\u8bba \uff09 Reference \u00b6 \u5173\u7cfb\u6a21\u578b","title":"\u5173\u7cfb\u6a21\u578b"},{"location":"retreat/relational-model/#relational-model","text":"\u5173\u7cfb\u6a21\u578b \uff08Relational Model\uff09\uff1a\u57fa\u4e8e \u8c13\u8bcd\u903b\u8f91 \u548c \u96c6\u5408\u8bba \u7684\u4e00\u79cd\u6570\u636e\u6a21\u578b\u3002 \u5173\u7cfb\u6a21\u578b \u7684\u57fa\u672c\u5047\u5b9a\u662f\u6240\u6709\u6570\u636e\u90fd\u8868\u793a\u4e3a\u6570\u5b66\u4e0a\u7684 \u5173\u7cfb \uff0c\u5c31\u662f\u8bf4 n \u4e2a\u96c6\u5408\u7684\u7b1b\u5361\u513f\u79ef\u7684\u4e00\u4e2a\u5b50\u96c6\uff1b\u6709\u5173\u8fd9\u79cd\u6570\u636e\u7684\u63a8\u7406\u901a\u8fc7\u4e8c\u503c\uff08\u5c31\u662f\u8bf4\u6ca1\u6709 NULL \uff09\u7684 \u8c13\u8bcd\u903b\u8f91 \u6765\u8fdb\u884c\uff0c\u8fd9\u610f\u5473\u7740\u5bf9\u6bcf\u4e2a\u547d\u9898\u90fd\u6709\u4e24\u79cd\u53ef\u80fd\u7684\u8ce6\u503c\uff1a\u8981\u4e48\u662f\u771f\u8981\u4e48\u662f\u5047\u3002 \u6570\u636e\u901a\u8fc7 \u5173\u7cfb\u6f14\u7b97 \u548c \u5173\u7cfb\u4ee3\u6570 \u65b9\u5f0f\u8fdb\u884c\u64cd\u4f5c\u3002 \u5173\u7cfb\u6f14\u7b97\uff08\u57fa\u4e8e \u8c13\u8bcd\u903b\u8f91 \uff09 \u5143\u7ec4\u5173\u7cfb\u6f14\u7b97\uff08\u884c\uff09 \u57df\u5173\u7cfb\u6f14\u7b97\uff08\u5217\uff09 \u5173\u7cfb\u4ee3\u6570\uff08\u57fa\u4e8e \u96c6\u5408\u8bba \uff09","title":"\u5173\u7cfb\u6a21\u578b\uff08Relational Model\uff09"},{"location":"retreat/relational-model/#reference","text":"\u5173\u7cfb\u6a21\u578b","title":"Reference"},{"location":"retreat/relational-rule/","text":"\u5173\u7cfb\u5b9a\u5f8b\uff08Relational Rule\uff09 \u00b6 \u67e5\u8be2\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u6811\uff1a \u5185\u90e8\u8282\u70b9\u662f\u7b97\u5b50 \u53f6\u5b50\u662f\u5173\u7cfb \u5b50\u6811\u662f\u5b50\u8868\u8fbe\u5f0f \u4e3b\u8981\u76ee\u6807\u662f\u628a\u8868\u8fbe\u5f0f\u6811\u53d8\u6362\u6210\u7b49\u4ef7\u7684\u8868\u8fbe\u5f0f\u6811\uff0c\u4f7f\u5f97\u5728\u6811\u4e2d\u7684\u5b50\u8868\u8fbe\u5f0f\u751f\u6210\u7684\u5173\u7cfb\u7684\u5e73\u5747\u5927\u5c0f\u6bd4\u4f18\u5316\u524d\u66f4\u5c0f\u3002\u6b21\u8981\u76ee\u6807\u662f\u5728\u4e00\u4e2a\u5355\u4e00\u67e5\u8be2\u4e2d\uff0c\u6216\u5728\u8981\u540c\u65f6\u6c42\u503c\u591a\u4e8e\u4e00\u4e2a\u67e5\u8be2\u7684\u65f6\u5019\u7684\u6240\u6709\u8fd9\u4e9b\u67e5\u8be2\u4e2d\uff0c\u5c1d\u8bd5\u5f62\u6210\u516c\u5171\u5b50\u8868\u8fbe\u5f0f\u3002\u5728\u6b21\u8981\u76ee\u6807\u80cc\u540e\u7684\u539f\u7406\u662f\u8ba1\u7b97\u516c\u5171\u5b50\u8868\u8fbe\u5f0f\u4e00\u6b21\u5c31\u591f\u4e86\uff0c\u5176\u7ed3\u679c\u53ef\u4ee5\u7528\u4e8e\u5305\u542b\u8fd9\u4e2a\u5b50\u8868\u8fbe\u5f0f\u7684\u6240\u6709\u67e5\u8be2\u4e2d\u3002 Rule \u00b6 \u7ed3\u5408\u5f8b\u4e0e\u4ea4\u6362\u5f8b\uff1a\u987a\u5e8f\u65e0\u5173\u3001\u7ed3\u679c\u4e00\u81f4 \u9009\u62e9\uff08Selection < \u03c3 >\uff09\uff1a\u5e42\u7b49\u6027\u3001\u4ea4\u6362\u6027\uff0c\u5206\u89e3\u3001\u4e0b\u63a8 \u6295\u5f71\uff08Projection < \u03c0 > \uff09\uff1a\u5e42\u7b49\u6027\uff0c\u6d88\u9664\u3001\u4e0b\u63a8 \u8fde\u63a5\uff08Join < \u22c8 >\uff09\uff1a\u79ef\u3001\u4e0b\u63a8 \u91cd\u590d\uff1a\u6d88\u9664\u3001\u4e0b\u63a8 \u5206\u7ec4\u3001\u805a\u96c6\uff1a\u6d88\u9664 \u7ed3\u5408\u3001\u5206\u914d Evaluate \u00b6 \u4e2d\u95f4\u5173\u7cfb \u9009\u62e9\u8fd0\u7b97 \u6295\u5f71\u8fd0\u7b97 \u8fde\u63a5\u8fd0\u7b97\uff1a\u591a\u8fde\u63a5\u3001\u591a\u5173\u7cfb \u4ea4\u3001\u5e76\u3001\u5dee \u6d88\u9664\u91cd\u590d \u5206\u7ec4\u3001\u805a\u96c6 Reference \u00b6 \u5173\u7cfb\u4ee3\u6570","title":"\u5173\u7cfb\u5b9a\u5f8b"},{"location":"retreat/relational-rule/#relational-rule","text":"\u67e5\u8be2\u53ef\u4ee5\u8868\u793a\u4e3a\u4e00\u4e2a\u6811\uff1a \u5185\u90e8\u8282\u70b9\u662f\u7b97\u5b50 \u53f6\u5b50\u662f\u5173\u7cfb \u5b50\u6811\u662f\u5b50\u8868\u8fbe\u5f0f \u4e3b\u8981\u76ee\u6807\u662f\u628a\u8868\u8fbe\u5f0f\u6811\u53d8\u6362\u6210\u7b49\u4ef7\u7684\u8868\u8fbe\u5f0f\u6811\uff0c\u4f7f\u5f97\u5728\u6811\u4e2d\u7684\u5b50\u8868\u8fbe\u5f0f\u751f\u6210\u7684\u5173\u7cfb\u7684\u5e73\u5747\u5927\u5c0f\u6bd4\u4f18\u5316\u524d\u66f4\u5c0f\u3002\u6b21\u8981\u76ee\u6807\u662f\u5728\u4e00\u4e2a\u5355\u4e00\u67e5\u8be2\u4e2d\uff0c\u6216\u5728\u8981\u540c\u65f6\u6c42\u503c\u591a\u4e8e\u4e00\u4e2a\u67e5\u8be2\u7684\u65f6\u5019\u7684\u6240\u6709\u8fd9\u4e9b\u67e5\u8be2\u4e2d\uff0c\u5c1d\u8bd5\u5f62\u6210\u516c\u5171\u5b50\u8868\u8fbe\u5f0f\u3002\u5728\u6b21\u8981\u76ee\u6807\u80cc\u540e\u7684\u539f\u7406\u662f\u8ba1\u7b97\u516c\u5171\u5b50\u8868\u8fbe\u5f0f\u4e00\u6b21\u5c31\u591f\u4e86\uff0c\u5176\u7ed3\u679c\u53ef\u4ee5\u7528\u4e8e\u5305\u542b\u8fd9\u4e2a\u5b50\u8868\u8fbe\u5f0f\u7684\u6240\u6709\u67e5\u8be2\u4e2d\u3002","title":"\u5173\u7cfb\u5b9a\u5f8b\uff08Relational Rule\uff09"},{"location":"retreat/relational-rule/#rule","text":"\u7ed3\u5408\u5f8b\u4e0e\u4ea4\u6362\u5f8b\uff1a\u987a\u5e8f\u65e0\u5173\u3001\u7ed3\u679c\u4e00\u81f4 \u9009\u62e9\uff08Selection < \u03c3 >\uff09\uff1a\u5e42\u7b49\u6027\u3001\u4ea4\u6362\u6027\uff0c\u5206\u89e3\u3001\u4e0b\u63a8 \u6295\u5f71\uff08Projection < \u03c0 > \uff09\uff1a\u5e42\u7b49\u6027\uff0c\u6d88\u9664\u3001\u4e0b\u63a8 \u8fde\u63a5\uff08Join < \u22c8 >\uff09\uff1a\u79ef\u3001\u4e0b\u63a8 \u91cd\u590d\uff1a\u6d88\u9664\u3001\u4e0b\u63a8 \u5206\u7ec4\u3001\u805a\u96c6\uff1a\u6d88\u9664 \u7ed3\u5408\u3001\u5206\u914d","title":"Rule"},{"location":"retreat/relational-rule/#evaluate","text":"\u4e2d\u95f4\u5173\u7cfb \u9009\u62e9\u8fd0\u7b97 \u6295\u5f71\u8fd0\u7b97 \u8fde\u63a5\u8fd0\u7b97\uff1a\u591a\u8fde\u63a5\u3001\u591a\u5173\u7cfb \u4ea4\u3001\u5e76\u3001\u5dee \u6d88\u9664\u91cd\u590d \u5206\u7ec4\u3001\u805a\u96c6","title":"Evaluate"},{"location":"retreat/relational-rule/#reference","text":"\u5173\u7cfb\u4ee3\u6570","title":"Reference"},{"location":"snappydata/overview/","text":"Overview \u00b6 Key Features \u00b6 100% compatible with Spar\uff1a\u4e0eSpark\u5b8c\u5168\u517c\u5bb9 In-memory row and column stores\uff1a\u57fa\u4e8e\u5185\u5b58\u7684\u884c\u5f0f\u548c\u5217\u5f0f\u5b58\u50a8 SQL standard compliance\uff1a\u652f\u6301\u6807\u51c6SQL\u548c\u4e30\u5bcc\u7684\u6269\u5c55 SQL based extensions for streaming processing\uff1a\u57fa\u4e8eSQL\u6d41\u5904\u7406\u7684\u6269\u5c55 Not-Only SQL\uff1a\u53ef\u4ee5\u4f5c\u4e3a\u6570\u636e\u5e93 Mutate, transact on data in Spark\uff1a\u652f\u6301\u4e8b\u52a1\u64cd\u4f5c Optimizations - Indexing\uff1a\u652f\u6301\u7d22\u5f15 Optimizations - colocation\uff1a\u6570\u636e\u672c\u6027\u5316 High availability not just Fault tolerance\uff1a\u6570\u636e\u5bb9\u9519\uff0c\u4fdd\u6301\u5e94\u7528\u8ba1\u7b97\u8fde\u7eed\u6027 Durability and recovery\uff1a\u8868\u53ef\u4ee5\u6301\u4e45\u5316\u5230\u78c1\u76d8\uff0c\u5728\u542f\u52a8\u65f6\u5019\u6062\u590d Interactive analytics using Synopsis Data Engine (SDE): \u6982\u8981\u6570\u636e\u5f15\u64ce Paper \u00b6 SnappyData: A Unified Cluster for Streaming, Transactions, and Interactive Analytics PDF \u3001 Slide Reference \u00b6 Docs Github SnappyData\u4e2d\u6587\u535a\u5ba2","title":"SnappyData"},{"location":"snappydata/overview/#overview","text":"","title":"Overview"},{"location":"snappydata/overview/#key-features","text":"100% compatible with Spar\uff1a\u4e0eSpark\u5b8c\u5168\u517c\u5bb9 In-memory row and column stores\uff1a\u57fa\u4e8e\u5185\u5b58\u7684\u884c\u5f0f\u548c\u5217\u5f0f\u5b58\u50a8 SQL standard compliance\uff1a\u652f\u6301\u6807\u51c6SQL\u548c\u4e30\u5bcc\u7684\u6269\u5c55 SQL based extensions for streaming processing\uff1a\u57fa\u4e8eSQL\u6d41\u5904\u7406\u7684\u6269\u5c55 Not-Only SQL\uff1a\u53ef\u4ee5\u4f5c\u4e3a\u6570\u636e\u5e93 Mutate, transact on data in Spark\uff1a\u652f\u6301\u4e8b\u52a1\u64cd\u4f5c Optimizations - Indexing\uff1a\u652f\u6301\u7d22\u5f15 Optimizations - colocation\uff1a\u6570\u636e\u672c\u6027\u5316 High availability not just Fault tolerance\uff1a\u6570\u636e\u5bb9\u9519\uff0c\u4fdd\u6301\u5e94\u7528\u8ba1\u7b97\u8fde\u7eed\u6027 Durability and recovery\uff1a\u8868\u53ef\u4ee5\u6301\u4e45\u5316\u5230\u78c1\u76d8\uff0c\u5728\u542f\u52a8\u65f6\u5019\u6062\u590d Interactive analytics using Synopsis Data Engine (SDE): \u6982\u8981\u6570\u636e\u5f15\u64ce","title":"Key Features"},{"location":"snappydata/overview/#paper","text":"SnappyData: A Unified Cluster for Streaming, Transactions, and Interactive Analytics PDF \u3001 Slide","title":"Paper"},{"location":"snappydata/overview/#reference","text":"Docs Github SnappyData\u4e2d\u6587\u535a\u5ba2","title":"Reference"},{"location":"spark/catalyst/","text":"Catalyst \u00b6 Encoder \u00b6 a container of serde expressions in Dataset Serialize\u3001Deserialize ExpressionEncoder(only) RowEncoder(mapping & convert external rows) InternalRow \u00b6 UnsafeRow(Tungsten) JoinedRow(Join) BaseGenericInternalRow GenericInternalRow SpecificInternalRow(modify) MutableUnsafeRow(update) TreeNode \u00b6 Expression QueryPlan LogicalPlan resolved\u3001canonicalized UnaryNode\u3001BinaryNode\u3001LeafNode\u3001Other SparkPlan UnaryExecNode\u3001BinaryExecNode\u3001LeafExecNode\u3001Other Rule \u00b6 Rule RuleExecutor Seq[Batch] Strategy Once FixedPoint Parser \u00b6 ANTLR(Lexer\u3001Parser)\uff1aAdaptive LL(*)\uff0cListener\u3001Visitor SQL\u3001Dataset\u3001DataFrame -> AstBuilder -> Unresolved LogicalPlan\uff08Relation\u3001Function\u3001Attribute\uff09 Analyzer \u00b6 Strategy\u3001Rule-Based Catalog\u3001Metastore\u3001Rule -> semantically validates and transforms(resolving, removing, modifying) -> Analyzed LogicalPlan Batch Strategy Rules Hints FixedPoint ResolveBroadcastHints\u3001ResolveCoalesceHints\u3001RemoveAllHints Simple Sanity Check Once LookupFunctions Substitution FixedPoint CTESubstitution\u3001WindowsSubstitution\u3001EliminateUnions\u3001SubstituteUnresolvedOrdinals Resolution FixedPoint ResolveTableValuedFunctions\u3001ResolveRelations\u3001ResolveReferences\u3001ResolveCreateNamedStruct\u3001ResolveDeserializer\u3001ResolveNewInstance\u3001ResolveUpCast\u3001ResolveGroupingAnalytics\u3001ResolvePivot\u3001ResolveOrdinalInOrderByAndGroupBy\u3001ResolveMissingReferences\u3001ExtractGenerator\u3001ResolveGenerate\u3001ResolveFunctions\u3001ResolveAliases\u3001ResolveSubquery\u3001ResolveWindowOrder\u3001ResolveWindowFrame\u3001ResolveNaturalAndUsingJoin\u3001ExtractWindowExpressions\u3001GlobalAggregates\u3001ResolveAggregateFunctions\u3001TimeWindowing\u3001ResolveInlineTables\u3001TypeCoercion.typeCoercionRules\u3001extendedResolutionRules Post-Hoc Resolution Once postHocResolutionRules View Once AliasViewChild Nondeterministic Once PullOutNondeterministic UDF Once HandleNullInputsForUDF FixNullability Once FixNullability ResolveTimeZone Once ResolveTimeZone Cleanup FixedPoint CleanupAliases Optimizer \u00b6 Analyzed LogicalPlan -> RBO(Rule-Based Optimizer) -> Optimized LogicalPlan Batch Strategy Rules Eliminate Distinct FixedPoint EliminateDistinct Finish Analysis Once EliminateSubqueryAliases\u3001EliminateView\u3001ReplaceExpressions\u3001ComputeCurrentTime\u3001GetCurrentDatabase\u3001RewriteDistinctAggregates\u3001ReplaceDeduplicateWithAggregate Union Once CombineUnions LocalRelation early FixedPoint ConvertToLocalRelation\u3001PropagateEmptyRelation Pullup Correlated Expressions Once PullupCorrelatedPredicates Subquery Once OptimizeSubqueries Replace Operators FixedPoint RewriteExceptAll\u3001RewriteIntersectAll\u3001ReplaceIntersectWithSemiJoin\u3001ReplaceExceptWithFilter\u3001ReplaceExceptWithAntiJoin\u3001ReplaceDistinctWithAggregate Aggregate FixedPoint RemoveLiteralFromGroupExpressions\u3001RemoveRepetitionFromGroupExpressions Join Reorder Once CostBasedJoinReorder Remove Redundant Sorts Once RemoveRedundantSorts Decimal Optimizations FixedPoint DecimalAggregates Object Expressions Optimization FixedPoint EliminateMapObjects\u3001CombineTypedFilters LocalRelation FixedPoint ConvertToLocalRelation\u3001PropagateEmptyRelation Extract PythonUDF From JoinCondition Once PullOutPythonUDFInJoinCondition Check Cartesian Products Once CheckCartesianProducts RewriteSubquery Once RewritePredicateSubquery\u3001ColumnPruning\u3001CollapseProject\u3001RemoveRedundantProject UpdateAttributeReferences Once UpdateNullabilityInAttributeReferences extendedOperatorOptimizationRules PushProjectionThroughUnion\u3001ReorderJoin\u3001EliminateOuterJoin\u3001PushPredicateThroughJoin\u3001PushDownPredicate\u3001LimitPushDown\u3001ColumnPruning\u3001CollapseRepartition\u3001CollapseProject\u3001CollapseWindow\u3001CombineFilters\u3001CombineLimits\u3001CombineUnions\u3001NullPropagation\u3001ConstantPropagation\u3001FoldablePropagation\u3001OptimizeIn\u3001ConstantFolding\u3001ReorderAssociativeOperator\u3001LikeSimplification\u3001BooleanSimplification\u3001SimplifyConditionals\u3001RemoveDispensableExpressions\u3001SimplifyBinaryComparison\u3001PruneFilters\u3001EliminateSorts\u3001SimplifyCasts\u3001SimplifyCaseConversionExpressions\u3001RewriteCorrelatedScalarSubquery\u3001EliminateSerialization\u3001RemoveRedundantAliases\u3001RemoveRedundantProject\u3001SimplifyExtractValueOps\u3001CombineConcats Non-Excludable PushProjectionThroughUnion\u3001EliminateDistinct\u3001EliminateSubqueryAliases\u3001EliminateView\u3001ReplaceExpressions\u3001ComputeCurrentTime\u3001GetCurrentDatabase\u3001RewriteDistinctAggregates\u3001ReplaceDeduplicateWithAggregate\u3001ReplaceIntersectWithSemiJoin\u3001ReplaceExceptWithFilter\u3001ReplaceExceptWithAntiJoin\u3001RewriteExceptAll\u3001RewriteIntersectAll\u3001ReplaceDistinctWithAggregate\u3001PullupCorrelatedPredicates\u3001RewriteCorrelatedScalarSubquery\u3001RewritePredicateSubquery\u3001PullOutPythonUDFInJoinCondition Planner & Execution \u00b6 CBO\uff08Cost-Based Optimizer\uff09\uff1aShuffle\u3001Join SparkPlan\u3001SparkPlaner\u3001QueryExecution Distribution\u3001Partitioning\u3001SortOrder SparkPlanInfo(metadata\u3001metrics) SparkStrategy(Aggregation\u3001BasicOperators\u3001FlatMapGroupsWithStateStrategy\u3001InMemoryScans\u3001JoinSelection\u3001SpecialLimits\u3001StatefulAggregationStrategy\u3001StreamingDeduplicationStrategy\u3001StreamingRelationStrategy) Rule(CollapseCodegenStages\u3001PlanSubqueries\u3001ReuseSubquery\u3001ReuseExchange\u3001EnsureRequirements) Aggregation \u00b6 Aggregation Buffer(Schema\u3001Attributes) Partial\u3001PartialMerge\u3001Final\u3001Complete Window \u00b6 windowSpec : name=identifier #windowRef | '('name=identifier')' #windowRef | '(' ( CLUSTER BY partition+=expression (',' partition+=expression)* | ((PARTITION | DISTRIBUTE) BY partition+=expression (',' partition+=expression)*)? ((ORDER | SORT) BY sortItem (',' sortItem)*)?) windowFrame? ')' #windowDef ; windowFrame : frameType=RANGE start=frameBound | frameType=ROWS start=frameBound | frameType=RANGE BETWEEN start=frameBound AND end=frameBound | frameType=ROWS BETWEEN start=frameBound AND end=frameBound ; frameBound : UNBOUNDED boundType=(PRECEDING | FOLLOWING) | boundType=CURRENT ROW | expression boundType=(PRECEDING | FOLLOWING) ; Join \u00b6 joinRelation : (joinType) JOIN right=relationPrimary joinCriteria? | NATURAL joinType JOIN right=relationPrimary ; joinType : INNER? | CROSS | LEFT OUTER? | LEFT SEMI | RIGHT OUTER? | FULL OUTER? | LEFT? ANTI ; joinCriteria : ON booleanExpression | USING identifierList ; Tungsten \u00b6 Memory Management and Binary Processing Cache-aware computation(CPU L1/L2/L3: Cache Hit, Cache Locality) Code generation(Janino\u3001WholeStageCodegen) No virtual function dispatches Intermediate data in memory vs CPU registers Loop unrolling and SIMD Columnar \u00b6 in-memory columnar format Codegen/Janino/JIT \u00b6 HashAggregate BroadcastHashJoin SortMergeJoin RDDScan DataSourceScan WholeStageCodegen Hint \u00b6 Join\u3001Shuffle BROADCASTJOIN\u3001MAPJOIN\u3001STREAMTABLE\u3001INDEX\u3001COALESCE\u3001REPARTITION Statistics \u00b6 Table(sizeInBytes\u3001rowCount\u3001hints) Column(distinctCount\u3001min\u3001max\u3001nullCount\u3001avgLen\u3001maxLen\u3001histogram) Adapter \u00b6 Metadata Metrics Data Source \u00b6 Federation Partitions Transactional Vectorization(Pushdown) Parquet ORC CarbonData Session \u00b6 Application -1:n-> Session(Context) -1:n-> Job Share & Cache Data Catalog \u00b6 Configuration View Function External Catalog Cache \u00b6 persist(StorageLevel.MEMORY_AND_DISK) Compression \u00b6 Cache tables in-memory columnar format Compression batchSize default 10000 ShuffleService \u00b6 Standalone Mode Executor Process Reference \u00b6 Spark SQL: Relational Data Processing in Spark Deep Dive into Spark SQL\u2019s Catalyst Optimizer Cost Based Optimizer in Apache Spark 2.2 Datasource V2 Series LL parser","title":"Catalyst"},{"location":"spark/catalyst/#catalyst","text":"","title":"Catalyst"},{"location":"spark/catalyst/#encoder","text":"a container of serde expressions in Dataset Serialize\u3001Deserialize ExpressionEncoder(only) RowEncoder(mapping & convert external rows)","title":"Encoder"},{"location":"spark/catalyst/#internalrow","text":"UnsafeRow(Tungsten) JoinedRow(Join) BaseGenericInternalRow GenericInternalRow SpecificInternalRow(modify) MutableUnsafeRow(update)","title":"InternalRow"},{"location":"spark/catalyst/#treenode","text":"Expression QueryPlan LogicalPlan resolved\u3001canonicalized UnaryNode\u3001BinaryNode\u3001LeafNode\u3001Other SparkPlan UnaryExecNode\u3001BinaryExecNode\u3001LeafExecNode\u3001Other","title":"TreeNode"},{"location":"spark/catalyst/#rule","text":"Rule RuleExecutor Seq[Batch] Strategy Once FixedPoint","title":"Rule"},{"location":"spark/catalyst/#parser","text":"ANTLR(Lexer\u3001Parser)\uff1aAdaptive LL(*)\uff0cListener\u3001Visitor SQL\u3001Dataset\u3001DataFrame -> AstBuilder -> Unresolved LogicalPlan\uff08Relation\u3001Function\u3001Attribute\uff09","title":"Parser"},{"location":"spark/catalyst/#analyzer","text":"Strategy\u3001Rule-Based Catalog\u3001Metastore\u3001Rule -> semantically validates and transforms(resolving, removing, modifying) -> Analyzed LogicalPlan Batch Strategy Rules Hints FixedPoint ResolveBroadcastHints\u3001ResolveCoalesceHints\u3001RemoveAllHints Simple Sanity Check Once LookupFunctions Substitution FixedPoint CTESubstitution\u3001WindowsSubstitution\u3001EliminateUnions\u3001SubstituteUnresolvedOrdinals Resolution FixedPoint ResolveTableValuedFunctions\u3001ResolveRelations\u3001ResolveReferences\u3001ResolveCreateNamedStruct\u3001ResolveDeserializer\u3001ResolveNewInstance\u3001ResolveUpCast\u3001ResolveGroupingAnalytics\u3001ResolvePivot\u3001ResolveOrdinalInOrderByAndGroupBy\u3001ResolveMissingReferences\u3001ExtractGenerator\u3001ResolveGenerate\u3001ResolveFunctions\u3001ResolveAliases\u3001ResolveSubquery\u3001ResolveWindowOrder\u3001ResolveWindowFrame\u3001ResolveNaturalAndUsingJoin\u3001ExtractWindowExpressions\u3001GlobalAggregates\u3001ResolveAggregateFunctions\u3001TimeWindowing\u3001ResolveInlineTables\u3001TypeCoercion.typeCoercionRules\u3001extendedResolutionRules Post-Hoc Resolution Once postHocResolutionRules View Once AliasViewChild Nondeterministic Once PullOutNondeterministic UDF Once HandleNullInputsForUDF FixNullability Once FixNullability ResolveTimeZone Once ResolveTimeZone Cleanup FixedPoint CleanupAliases","title":"Analyzer"},{"location":"spark/catalyst/#optimizer","text":"Analyzed LogicalPlan -> RBO(Rule-Based Optimizer) -> Optimized LogicalPlan Batch Strategy Rules Eliminate Distinct FixedPoint EliminateDistinct Finish Analysis Once EliminateSubqueryAliases\u3001EliminateView\u3001ReplaceExpressions\u3001ComputeCurrentTime\u3001GetCurrentDatabase\u3001RewriteDistinctAggregates\u3001ReplaceDeduplicateWithAggregate Union Once CombineUnions LocalRelation early FixedPoint ConvertToLocalRelation\u3001PropagateEmptyRelation Pullup Correlated Expressions Once PullupCorrelatedPredicates Subquery Once OptimizeSubqueries Replace Operators FixedPoint RewriteExceptAll\u3001RewriteIntersectAll\u3001ReplaceIntersectWithSemiJoin\u3001ReplaceExceptWithFilter\u3001ReplaceExceptWithAntiJoin\u3001ReplaceDistinctWithAggregate Aggregate FixedPoint RemoveLiteralFromGroupExpressions\u3001RemoveRepetitionFromGroupExpressions Join Reorder Once CostBasedJoinReorder Remove Redundant Sorts Once RemoveRedundantSorts Decimal Optimizations FixedPoint DecimalAggregates Object Expressions Optimization FixedPoint EliminateMapObjects\u3001CombineTypedFilters LocalRelation FixedPoint ConvertToLocalRelation\u3001PropagateEmptyRelation Extract PythonUDF From JoinCondition Once PullOutPythonUDFInJoinCondition Check Cartesian Products Once CheckCartesianProducts RewriteSubquery Once RewritePredicateSubquery\u3001ColumnPruning\u3001CollapseProject\u3001RemoveRedundantProject UpdateAttributeReferences Once UpdateNullabilityInAttributeReferences extendedOperatorOptimizationRules PushProjectionThroughUnion\u3001ReorderJoin\u3001EliminateOuterJoin\u3001PushPredicateThroughJoin\u3001PushDownPredicate\u3001LimitPushDown\u3001ColumnPruning\u3001CollapseRepartition\u3001CollapseProject\u3001CollapseWindow\u3001CombineFilters\u3001CombineLimits\u3001CombineUnions\u3001NullPropagation\u3001ConstantPropagation\u3001FoldablePropagation\u3001OptimizeIn\u3001ConstantFolding\u3001ReorderAssociativeOperator\u3001LikeSimplification\u3001BooleanSimplification\u3001SimplifyConditionals\u3001RemoveDispensableExpressions\u3001SimplifyBinaryComparison\u3001PruneFilters\u3001EliminateSorts\u3001SimplifyCasts\u3001SimplifyCaseConversionExpressions\u3001RewriteCorrelatedScalarSubquery\u3001EliminateSerialization\u3001RemoveRedundantAliases\u3001RemoveRedundantProject\u3001SimplifyExtractValueOps\u3001CombineConcats Non-Excludable PushProjectionThroughUnion\u3001EliminateDistinct\u3001EliminateSubqueryAliases\u3001EliminateView\u3001ReplaceExpressions\u3001ComputeCurrentTime\u3001GetCurrentDatabase\u3001RewriteDistinctAggregates\u3001ReplaceDeduplicateWithAggregate\u3001ReplaceIntersectWithSemiJoin\u3001ReplaceExceptWithFilter\u3001ReplaceExceptWithAntiJoin\u3001RewriteExceptAll\u3001RewriteIntersectAll\u3001ReplaceDistinctWithAggregate\u3001PullupCorrelatedPredicates\u3001RewriteCorrelatedScalarSubquery\u3001RewritePredicateSubquery\u3001PullOutPythonUDFInJoinCondition","title":"Optimizer"},{"location":"spark/catalyst/#planner-execution","text":"CBO\uff08Cost-Based Optimizer\uff09\uff1aShuffle\u3001Join SparkPlan\u3001SparkPlaner\u3001QueryExecution Distribution\u3001Partitioning\u3001SortOrder SparkPlanInfo(metadata\u3001metrics) SparkStrategy(Aggregation\u3001BasicOperators\u3001FlatMapGroupsWithStateStrategy\u3001InMemoryScans\u3001JoinSelection\u3001SpecialLimits\u3001StatefulAggregationStrategy\u3001StreamingDeduplicationStrategy\u3001StreamingRelationStrategy) Rule(CollapseCodegenStages\u3001PlanSubqueries\u3001ReuseSubquery\u3001ReuseExchange\u3001EnsureRequirements)","title":"Planner &amp; Execution"},{"location":"spark/catalyst/#aggregation","text":"Aggregation Buffer(Schema\u3001Attributes) Partial\u3001PartialMerge\u3001Final\u3001Complete","title":"Aggregation"},{"location":"spark/catalyst/#window","text":"windowSpec : name=identifier #windowRef | '('name=identifier')' #windowRef | '(' ( CLUSTER BY partition+=expression (',' partition+=expression)* | ((PARTITION | DISTRIBUTE) BY partition+=expression (',' partition+=expression)*)? ((ORDER | SORT) BY sortItem (',' sortItem)*)?) windowFrame? ')' #windowDef ; windowFrame : frameType=RANGE start=frameBound | frameType=ROWS start=frameBound | frameType=RANGE BETWEEN start=frameBound AND end=frameBound | frameType=ROWS BETWEEN start=frameBound AND end=frameBound ; frameBound : UNBOUNDED boundType=(PRECEDING | FOLLOWING) | boundType=CURRENT ROW | expression boundType=(PRECEDING | FOLLOWING) ;","title":"Window"},{"location":"spark/catalyst/#join","text":"joinRelation : (joinType) JOIN right=relationPrimary joinCriteria? | NATURAL joinType JOIN right=relationPrimary ; joinType : INNER? | CROSS | LEFT OUTER? | LEFT SEMI | RIGHT OUTER? | FULL OUTER? | LEFT? ANTI ; joinCriteria : ON booleanExpression | USING identifierList ;","title":"Join"},{"location":"spark/catalyst/#tungsten","text":"Memory Management and Binary Processing Cache-aware computation(CPU L1/L2/L3: Cache Hit, Cache Locality) Code generation(Janino\u3001WholeStageCodegen) No virtual function dispatches Intermediate data in memory vs CPU registers Loop unrolling and SIMD","title":"Tungsten"},{"location":"spark/catalyst/#columnar","text":"in-memory columnar format","title":"Columnar"},{"location":"spark/catalyst/#codegenjaninojit","text":"HashAggregate BroadcastHashJoin SortMergeJoin RDDScan DataSourceScan WholeStageCodegen","title":"Codegen/Janino/JIT"},{"location":"spark/catalyst/#hint","text":"Join\u3001Shuffle BROADCASTJOIN\u3001MAPJOIN\u3001STREAMTABLE\u3001INDEX\u3001COALESCE\u3001REPARTITION","title":"Hint"},{"location":"spark/catalyst/#statistics","text":"Table(sizeInBytes\u3001rowCount\u3001hints) Column(distinctCount\u3001min\u3001max\u3001nullCount\u3001avgLen\u3001maxLen\u3001histogram)","title":"Statistics"},{"location":"spark/catalyst/#adapter","text":"Metadata Metrics","title":"Adapter"},{"location":"spark/catalyst/#data-source","text":"Federation Partitions Transactional Vectorization(Pushdown) Parquet ORC CarbonData","title":"Data Source"},{"location":"spark/catalyst/#session","text":"Application -1:n-> Session(Context) -1:n-> Job Share & Cache Data","title":"Session"},{"location":"spark/catalyst/#catalog","text":"Configuration View Function External Catalog","title":"Catalog"},{"location":"spark/catalyst/#cache","text":"persist(StorageLevel.MEMORY_AND_DISK)","title":"Cache"},{"location":"spark/catalyst/#compression","text":"Cache tables in-memory columnar format Compression batchSize default 10000","title":"Compression"},{"location":"spark/catalyst/#shuffleservice","text":"Standalone Mode Executor Process","title":"ShuffleService"},{"location":"spark/catalyst/#reference","text":"Spark SQL: Relational Data Processing in Spark Deep Dive into Spark SQL\u2019s Catalyst Optimizer Cost Based Optimizer in Apache Spark 2.2 Datasource V2 Series LL parser","title":"Reference"},{"location":"spark/compute/","text":"\u8ba1\u7b97\uff08Compute\uff09 \u00b6 RDD \u00b6 Characteristics \u00b6 \u5206\u5e03\uff08Partitions\uff09 \u672c\u5730\u5316\uff08PreferredLocations\uff09 \u4f9d\u8d56\uff08Dependencies\uff09 \u8fed\u4ee3\uff08Iterator\uff09 \u5206\u533a\uff08Partitioner\uff09 Operations \u00b6 Creation Transformation Storage Action Dependencies \u00b6 Narrow Dependencies Shuffle/Wide Dependencies Stage \u00b6 ResultStage ShuffleMapStage DAG \u00b6 Lineage Fault Tolerance Data Dependency Shuffle \u00b6 Read/Write Server/Client Pull/Push Tungsten \u00b6 Memory Management and Binary Processing Cache-aware computation Code generation No virtual function dispatches Intermediate data in memory vs CPU registers Loop unrolling and SIMD Reference \u00b6 Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing","title":"\u8ba1\u7b97"},{"location":"spark/compute/#compute","text":"","title":"\u8ba1\u7b97\uff08Compute\uff09"},{"location":"spark/compute/#rdd","text":"","title":"RDD"},{"location":"spark/compute/#characteristics","text":"\u5206\u5e03\uff08Partitions\uff09 \u672c\u5730\u5316\uff08PreferredLocations\uff09 \u4f9d\u8d56\uff08Dependencies\uff09 \u8fed\u4ee3\uff08Iterator\uff09 \u5206\u533a\uff08Partitioner\uff09","title":"Characteristics"},{"location":"spark/compute/#operations","text":"Creation Transformation Storage Action","title":"Operations"},{"location":"spark/compute/#dependencies","text":"Narrow Dependencies Shuffle/Wide Dependencies","title":"Dependencies"},{"location":"spark/compute/#stage","text":"ResultStage ShuffleMapStage","title":"Stage"},{"location":"spark/compute/#dag","text":"Lineage Fault Tolerance Data Dependency","title":"DAG"},{"location":"spark/compute/#shuffle","text":"Read/Write Server/Client Pull/Push","title":"Shuffle"},{"location":"spark/compute/#tungsten","text":"Memory Management and Binary Processing Cache-aware computation Code generation No virtual function dispatches Intermediate data in memory vs CPU registers Loop unrolling and SIMD","title":"Tungsten"},{"location":"spark/compute/#reference","text":"Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing","title":"Reference"},{"location":"spark/metrics/","text":"\u5ea6\u91cf\uff08Metrics\uff09 \u00b6 Listeners \u00b6 ListenerBus\u3001SparkListenerBus\u3001LiveListenerBus SparkListener\u3001SparkListenerEvent Environment\u3001Job\u3001Stage\u3001Task\u3001BlockManager\u3001Application\u3001Executor ... Source \u00b6 Master Applications Worker Executor Driver ShuffleService Sink \u00b6 ConsoleSink CSVSink JmxSink MetricsServlet GraphiteSink Slf4jSink StatsdSink Web UI & REST API \u00b6 Applications Jobs Stages Executors Storage Environment Streaming SQL Reference \u00b6 Monitoring and Instrumentation Dr. Elephant Sparklint","title":"\u5ea6\u91cf"},{"location":"spark/metrics/#metrics","text":"","title":"\u5ea6\u91cf\uff08Metrics\uff09"},{"location":"spark/metrics/#listeners","text":"ListenerBus\u3001SparkListenerBus\u3001LiveListenerBus SparkListener\u3001SparkListenerEvent Environment\u3001Job\u3001Stage\u3001Task\u3001BlockManager\u3001Application\u3001Executor ...","title":"Listeners"},{"location":"spark/metrics/#source","text":"Master Applications Worker Executor Driver ShuffleService","title":"Source"},{"location":"spark/metrics/#sink","text":"ConsoleSink CSVSink JmxSink MetricsServlet GraphiteSink Slf4jSink StatsdSink","title":"Sink"},{"location":"spark/metrics/#web-ui-rest-api","text":"Applications Jobs Stages Executors Storage Environment Streaming SQL","title":"Web UI &amp; REST API"},{"location":"spark/metrics/#reference","text":"Monitoring and Instrumentation Dr. Elephant Sparklint","title":"Reference"},{"location":"spark/network/","text":"\u7f51\u7edc\uff08Network\uff09 \u00b6 \u89d2\u8272\uff08Role\uff09 \u00b6 Master, Worker, Client, Driver, Executor RPC \u00b6 \u57fa\u4e8eNetty Context\uff08\u4e0a\u4e0b\u6587\uff1aLocal\u3001Remote\uff09 Env\uff08\u8fd0\u884c\u73af\u5883\uff09 Endpoint\uff08\u7ec8\u7aef\uff09 \u4e3b\u8981\u4f5c\u7528 \u00b6 \u6d88\u606f\u4e92\u901a\uff1aEvent\u3001Status \u6587\u4ef6\u4f20\u8f93\uff1aFetch\u3001Upload Block\uff1aStore\u3001Replication Shuffle\uff1aWriter\u3001Reader Reference \u00b6 \u6df1\u5165\u89e3\u6790Spark\u4e2d\u7684RPC","title":"\u7f51\u7edc"},{"location":"spark/network/#network","text":"","title":"\u7f51\u7edc\uff08Network\uff09"},{"location":"spark/network/#role","text":"Master, Worker, Client, Driver, Executor","title":"\u89d2\u8272\uff08Role\uff09"},{"location":"spark/network/#rpc","text":"\u57fa\u4e8eNetty Context\uff08\u4e0a\u4e0b\u6587\uff1aLocal\u3001Remote\uff09 Env\uff08\u8fd0\u884c\u73af\u5883\uff09 Endpoint\uff08\u7ec8\u7aef\uff09","title":"RPC"},{"location":"spark/network/#_1","text":"\u6d88\u606f\u4e92\u901a\uff1aEvent\u3001Status \u6587\u4ef6\u4f20\u8f93\uff1aFetch\u3001Upload Block\uff1aStore\u3001Replication Shuffle\uff1aWriter\u3001Reader","title":"\u4e3b\u8981\u4f5c\u7528"},{"location":"spark/network/#reference","text":"\u6df1\u5165\u89e3\u6790Spark\u4e2d\u7684RPC","title":"Reference"},{"location":"spark/schedule/","text":"\u8c03\u5ea6\uff08Schedule\uff09 \u00b6 Reference\uff1a \u00b6","title":"\u8c03\u5ea6"},{"location":"spark/schedule/#schedule","text":"","title":"\u8c03\u5ea6\uff08Schedule\uff09"},{"location":"spark/schedule/#reference","text":"","title":"Reference\uff1a"},{"location":"spark/storage/","text":"\u5b58\u50a8\uff08Storage\uff09 \u00b6 \u5b58\u50a8\u7ea7\u522b\uff08Storage Level\uff09 \u00b6 Disk Memory OffHeap(Unsafe\u3001Zero-copy) Serialization Replication \u64cd\u4f5c\uff08Operation\uff09 \u00b6 LRU(Least Recently Used) Cache(persist(StorageLevel.MEMORY_AND_DISK)) Persist(persist/unPersist/destroy) Checkpoint \u5b58\u50a8\uff08Store\uff09 \u00b6 Disk Memory(OnHeap/OffHeap) \u7edf\u4e00\u5185\u5b58\u7ba1\u7406\uff08Unified Memory Management\uff09 \u00b6 Execution Storage \u4f1a\u8bdd\uff08Session\uff09 \u00b6 Metastore Local Session Global Session \u6d17\u724c\uff08Shuffle\uff09 \u00b6 Read/Write Server/Client Pull/Push Reference \u00b6 Apache Spark \u5185\u5b58\u7ba1\u7406\u8be6\u89e3 Spark Storage \u2460 - Spark Storage \u6a21\u5757\u6574\u4f53\u67b6\u6784 Spark Storage \u2461 - BlockManager \u7684\u521b\u5efa\u4e0e\u6ce8\u518c Spark Storage \u2462 - Master \u4e0e Slave \u4e4b\u95f4\u7684\u6d88\u606f\u4f20\u9012\u4e0e\u65f6\u673a Spark Storage \u2463 - \u5b58\u50a8\u6267\u884c\u7c7b\u4ecb\u7ecd\uff08DiskBlockManager\u3001DiskStore\u3001MemoryStore\uff09 Spark \u5185\u5b58\u7ba1\u7406\u7684\u524d\u4e16\u4eca\u751f\uff08\u4e0a\uff09 Spark \u5185\u5b58\u7ba1\u7406\u7684\u524d\u4e16\u4eca\u751f\uff08\u4e0b\uff09","title":"\u5b58\u50a8"},{"location":"spark/storage/#storage","text":"","title":"\u5b58\u50a8\uff08Storage\uff09"},{"location":"spark/storage/#storage-level","text":"Disk Memory OffHeap(Unsafe\u3001Zero-copy) Serialization Replication","title":"\u5b58\u50a8\u7ea7\u522b\uff08Storage Level\uff09"},{"location":"spark/storage/#operation","text":"LRU(Least Recently Used) Cache(persist(StorageLevel.MEMORY_AND_DISK)) Persist(persist/unPersist/destroy) Checkpoint","title":"\u64cd\u4f5c\uff08Operation\uff09"},{"location":"spark/storage/#store","text":"Disk Memory(OnHeap/OffHeap)","title":"\u5b58\u50a8\uff08Store\uff09"},{"location":"spark/storage/#unified-memory-management","text":"Execution Storage","title":"\u7edf\u4e00\u5185\u5b58\u7ba1\u7406\uff08Unified Memory Management\uff09"},{"location":"spark/storage/#session","text":"Metastore Local Session Global Session","title":"\u4f1a\u8bdd\uff08Session\uff09"},{"location":"spark/storage/#shuffle","text":"Read/Write Server/Client Pull/Push","title":"\u6d17\u724c\uff08Shuffle\uff09"},{"location":"spark/storage/#reference","text":"Apache Spark \u5185\u5b58\u7ba1\u7406\u8be6\u89e3 Spark Storage \u2460 - Spark Storage \u6a21\u5757\u6574\u4f53\u67b6\u6784 Spark Storage \u2461 - BlockManager \u7684\u521b\u5efa\u4e0e\u6ce8\u518c Spark Storage \u2462 - Master \u4e0e Slave \u4e4b\u95f4\u7684\u6d88\u606f\u4f20\u9012\u4e0e\u65f6\u673a Spark Storage \u2463 - \u5b58\u50a8\u6267\u884c\u7c7b\u4ecb\u7ecd\uff08DiskBlockManager\u3001DiskStore\u3001MemoryStore\uff09 Spark \u5185\u5b58\u7ba1\u7406\u7684\u524d\u4e16\u4eca\u751f\uff08\u4e0a\uff09 Spark \u5185\u5b58\u7ba1\u7406\u7684\u524d\u4e16\u4eca\u751f\uff08\u4e0b\uff09","title":"Reference"},{"location":"special/","text":"\u7d22\u5f15 \u00b6 \u7c7b\u578b \u00b6 \u805a\u96c6\u7d22\u5f15\u3001\u975e\u805a\u96c6\u7d22\u5f15 \u7a20\u5bc6\u7d22\u5f15\u3001\u7a00\u758f\u7d22\u5f15 B+Tree LSM-Tree \u7a7a\u95f4\u7d22\u5f15\uff08R-Tree\u3001GeoHash\uff09 \u54c8\u5e0c\u7d22\u5f15\uff08Hash\uff09 \u5c40\u90e8\u654f\u611f\u54c8\u5e0c\uff08Locality Sensitive Hashing\uff09 SimHash MinHash \u4f4d\u56fe\u7d22\u5f15\uff08BitMap\uff09 \u5012\u6392\u7d22\u5f15\uff08Inverted\uff09 BloomFilter SkipList \u5176\u4ed6 \u00b6 \u67e5\u627e \u6392\u5e8f \u7ebf\u6027\u8868\uff08List\uff09 \u5806\uff08Heap\uff09 \u6811 \u7ea2\u9ed1\u6811\uff08Red\u2013black Tree\uff09 \u5b57\u5178\u6811\uff08Trie Tree\uff09 Reference \u00b6 MySQL\u7d22\u5f15\u80cc\u540e\u7684\u6570\u636e\u7ed3\u6784\u53ca\u7b97\u6cd5\u539f\u7406","title":"\u7d22\u5f15"},{"location":"special/#_1","text":"","title":"\u7d22\u5f15"},{"location":"special/#_2","text":"\u805a\u96c6\u7d22\u5f15\u3001\u975e\u805a\u96c6\u7d22\u5f15 \u7a20\u5bc6\u7d22\u5f15\u3001\u7a00\u758f\u7d22\u5f15 B+Tree LSM-Tree \u7a7a\u95f4\u7d22\u5f15\uff08R-Tree\u3001GeoHash\uff09 \u54c8\u5e0c\u7d22\u5f15\uff08Hash\uff09 \u5c40\u90e8\u654f\u611f\u54c8\u5e0c\uff08Locality Sensitive Hashing\uff09 SimHash MinHash \u4f4d\u56fe\u7d22\u5f15\uff08BitMap\uff09 \u5012\u6392\u7d22\u5f15\uff08Inverted\uff09 BloomFilter SkipList","title":"\u7c7b\u578b"},{"location":"special/#_3","text":"\u67e5\u627e \u6392\u5e8f \u7ebf\u6027\u8868\uff08List\uff09 \u5806\uff08Heap\uff09 \u6811 \u7ea2\u9ed1\u6811\uff08Red\u2013black Tree\uff09 \u5b57\u5178\u6811\uff08Trie Tree\uff09","title":"\u5176\u4ed6"},{"location":"special/#reference","text":"MySQL\u7d22\u5f15\u80cc\u540e\u7684\u6570\u636e\u7ed3\u6784\u53ca\u7b97\u6cd5\u539f\u7406","title":"Reference"},{"location":"special/storege/","text":"\u5b58\u50a8 \u00b6 NSM\uff1aRow-oriented\uff0cOLTP DSM\uff1aColumn-oriented\uff0cOLAP HTAP\uff1a PAX\uff08Partition Attributes Across\uff09 Reference \u00b6 \u6570\u636e\u5e93\u4ece0\u52300.1 (\u4e8c)\uff1aOLTP VS OLAP VS HTAP \u5904\u7406\u6d77\u91cf\u6570\u636e\uff1a\u5217\u5f0f\u5b58\u50a8\u7efc\u8ff0\uff08\u5b58\u50a8\u7bc7\uff09","title":"\u5b58\u50a8"},{"location":"special/storege/#_1","text":"NSM\uff1aRow-oriented\uff0cOLTP DSM\uff1aColumn-oriented\uff0cOLAP HTAP\uff1a PAX\uff08Partition Attributes Across\uff09","title":"\u5b58\u50a8"},{"location":"special/storege/#reference","text":"\u6570\u636e\u5e93\u4ece0\u52300.1 (\u4e8c)\uff1aOLTP VS OLAP VS HTAP \u5904\u7406\u6d77\u91cf\u6570\u636e\uff1a\u5217\u5f0f\u5b58\u50a8\u7efc\u8ff0\uff08\u5b58\u50a8\u7bc7\uff09","title":"Reference"},{"location":"tidb/overview/","text":"TODO \u00b6 Reference \u00b6 Docs - Github Blog - Github","title":"TiDB"},{"location":"tidb/overview/#todo","text":"","title":"TODO"},{"location":"tidb/overview/#reference","text":"Docs - Github Blog - Github","title":"Reference"}]}